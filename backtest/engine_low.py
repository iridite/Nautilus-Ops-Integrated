import gc
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

logger = logging.getLogger(__name__)
from nautilus_trader.analysis.tearsheet import create_tearsheet
from nautilus_trader.backtest.config import BacktestEngineConfig
from nautilus_trader.backtest.engine import BacktestEngine
from nautilus_trader.backtest.models.fee import MakerTakerFeeModel
from nautilus_trader.common.config import LoggingConfig
from nautilus_trader.config import RiskEngineConfig
from nautilus_trader.model import BarType, TraderId
from nautilus_trader.model.currencies import USDT
from nautilus_trader.model.enums import (
    AccountType,
    BookType,
    OmsType,
)
from nautilus_trader.model.identifiers import Venue
from nautilus_trader.model.instruments import Instrument
from nautilus_trader.persistence.wranglers import BarDataWrangler
from pandas import DataFrame

from backtest.exceptions import (
    BacktestEngineError,
    CustomDataError,
    DataLoadError,
    InstrumentLoadError,
)
from core.schemas import BacktestConfig, DataConfig
from strategy.core.loader import (
    filter_strategy_params,
    load_strategy_class,
    load_strategy_config_class,
)
from utils.data_management.data_loader import load_ohlcv_csv
from utils.instrument_loader import load_instrument
from utils.oi_funding_adapter import OIFundingDataLoader


def _load_data_for_feed(
    engine: BacktestEngine,
    base_dir: Path,
    cfg: BacktestConfig,
    data_cfg: DataConfig,
    loaded_instruments: Dict[str, Instrument],
) -> Optional[BarType]:
    """
    åŠ è½½ CSV æ•°æ®å¹¶æ³¨å…¥å›æµ‹å¼•æ“ (Low-Level Engine é£æ ¼)

    Args:
        engine: BacktestEngine å®ä¾‹
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        cfg: å›æµ‹é…ç½®
        data_cfg: æ•°æ®é…ç½®
        loaded_instruments: å·²åŠ è½½çš„æ ‡çš„æ˜ å°„

    Returns:
        Optional[BarType]: æˆåŠŸåŠ è½½åˆ™è¿”å› BarTypeï¼Œå¦åˆ™è¿”å› None

    Raises:
        DataLoadError: å½“æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    # ç¡®å®šå…³è”çš„ Instrument ID
    inst_id_str = data_cfg.instrument_id or str(cfg.instrument.instrument_id)
    inst = loaded_instruments.get(inst_id_str)
    if not inst:
        raise DataLoadError(f"Instrument {inst_id_str} not found for feed {data_cfg.csv_file_name}")

    feed_bar_type_str = f"{inst.id}-{data_cfg.bar_type_str}"
    feed_bar_type = BarType.from_str(feed_bar_type_str)

    csv_path = data_cfg.full_path
    if not csv_path.exists():
        raise DataLoadError(f"CSV file not found: {csv_path}", str(csv_path))

    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®åŠ è½½å™¨ (æ™ºèƒ½æ—¶é—´åˆ—æ£€æµ‹ + ä¼˜åŒ–åŠ è½½)
        df: DataFrame = load_ohlcv_csv(
            csv_path=csv_path,
            start_date=cfg.start_date,
            end_date=cfg.end_date,
        )

        if len(df) == 0:
            raise DataLoadError(f"No data available in range for {data_cfg.csv_file_name}", str(csv_path))

        # ä½¿ç”¨ Wrangler è½¬æ¢å¹¶æ³¨å…¥å¼•æ“
        wrangler = BarDataWrangler(feed_bar_type, inst)
        bars = wrangler.process(df)
        engine.add_data(bars)

        logger.info(f"âœ… Loaded {len(bars)} bars for {inst.id} ({data_cfg.label})")
        return feed_bar_type

    except Exception as e:
        if isinstance(e, DataLoadError):
            raise
        raise DataLoadError(f"Error loading {data_cfg.csv_file_name}: {e}", str(csv_path), e)


def _load_custom_data_to_engine(
    cfg: BacktestConfig,
    base_dir: Path,
    engine: BacktestEngine,
    loaded_instruments: Dict[str, Instrument],
) -> int:
    """
    åŠ è½½è‡ªå®šä¹‰æ•°æ®(OI, Funding Rate)åˆ°å›æµ‹å¼•æ“ (Low-Level Engine é£æ ¼)

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        engine: BacktestEngine å®ä¾‹
        loaded_instruments: å·²åŠ è½½çš„æ ‡çš„æ˜ å°„

    Returns:
        int: åŠ è½½çš„æ•°æ®ç‚¹æ€»æ•°

    Raises:
        CustomDataError: å½“è‡ªå®šä¹‰æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    if not (cfg.start_date and cfg.end_date):
        logger.warning("âš ï¸ No date range specified, skipping custom data loading")
        return 0

    logger.info("ğŸ“Š Loading custom data (OI, Funding Rate)...")

    try:
        from utils.oi_funding_adapter import merge_custom_data_with_bars

        data_dir = base_dir / "data" / "raw"
        total_loaded = 0

        for inst_id_str, inst in loaded_instruments.items():
            instrument_id = inst.id
            symbol = str(instrument_id.symbol).split("-")[0]  # BTCUSDT-PERP -> BTCUSDT
            symbol_dir = data_dir / symbol

            if not symbol_dir.exists():
                continue

            # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
            oi_files = list(symbol_dir.glob("*-oi-1h-*.csv"))
            funding_files = list(symbol_dir.glob("*-funding-*.csv"))

            oi_data_list = []
            funding_data_list = []

            # åŠ è½½OIæ•°æ®
            if oi_files:
                loader = OIFundingDataLoader(base_dir)
                for oi_file in oi_files:
                    oi_data_list.extend(loader.load_oi_data(
                        symbol=symbol,
                        instrument_id=instrument_id,
                        start_date=cfg.start_date,
                        end_date=cfg.end_date,
                        exchange=cfg.instrument.venue_name.lower() if cfg.instrument else "binance"
                    ))

            # åŠ è½½Funding Rateæ•°æ®
            if funding_files:
                loader = OIFundingDataLoader(base_dir)
                for funding_file in funding_files:
                    funding_data_list.extend(loader.load_funding_data(
                        symbol=symbol,
                        instrument_id=instrument_id,
                        start_date=cfg.start_date,
                        end_date=cfg.end_date,
                        exchange=cfg.instrument.venue_name.lower() if cfg.instrument else "binance"
                    ))

            # åˆå¹¶å¹¶æ·»åŠ åˆ°å¼•æ“
            if oi_data_list or funding_data_list:
                merged_data = merge_custom_data_with_bars(oi_data_list, funding_data_list)
                engine.add_data(merged_data)
                total_loaded += len(merged_data)
                logger.info(f"   âœ… Added {len(merged_data)} custom data points for {symbol}")

        logger.info(f"âœ… Total custom data loaded: {total_loaded} points")
        return total_loaded

    except Exception as e:
        raise CustomDataError(f"Custom data loading failed: {e}", cause=e)




def _process_backtest_results(
    cfg: BacktestConfig,
    base_dir: Path,
    engine: BacktestEngine,
) -> None:
    """
    å¤„ç†å›æµ‹ç»“æœ (Low-Level Engine é£æ ¼)

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        engine: BacktestEngine å®ä¾‹
    """
    try:
        # ç®€åŒ–çš„ç»“æœå¤„ç† - åªä¿å­˜åŸºæœ¬ç»Ÿè®¡
        result_dict = {
            "meta": {
                "strategy_name": cfg.strategy.name,
                "timestamp": datetime.now().isoformat(),
                "engine_type": "low_level",
            },
            "summary": {
                "start_date": cfg.start_date,
                "end_date": cfg.end_date,
                "initial_balances": [str(balance) for balance in cfg.initial_balances],
            },
            "strategy_config": cfg.strategy.params if hasattr(cfg.strategy.params, "dict")
                               else cfg.strategy.params,
        }

        # ä¿å­˜ JSON ç»“æœ
        result_dir = base_dir / "output" / "backtest" / "result"
        result_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"{cfg.strategy.name}_{timestamp}.json"
        filepath = result_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(result_dict, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"ğŸ“ Results saved to: {filepath}")

    except Exception as e:
        logger.warning(f"âš ï¸ Error saving results: {e}")


def run_low_level(cfg: BacktestConfig, base_dir: Path):
    """
    è¿è¡Œä½çº§å¼•æ“å›æµ‹ (Low-level Engine)

    ä¿æŒ BacktestEngine ç›´æ¥ API çš„ç®€æ´ç‰¹æ€§ï¼Œä½†å¢å¼ºé”™è¯¯å¤„ç†å’ŒåŠŸèƒ½å®Œæ•´æ€§ã€‚

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•

    Raises:
        BacktestEngineError: å½“å›æµ‹æ‰§è¡Œå¤±è´¥æ—¶
        InstrumentLoadError: å½“æ ‡çš„åŠ è½½å¤±è´¥æ—¶
        DataLoadError: å½“æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    logger.info(f"ğŸš€ Starting Low-Level Backtest: {cfg.strategy.name}")

    try:
        # 1. é…ç½®æ—¥å¿—ç³»ç»Ÿ
        logging_config = None
        if cfg.logging:
            logging_config = LoggingConfig(
                log_level=cfg.logging.log_level,
                log_level_file=cfg.logging.log_level_file,
                log_directory=str(base_dir / "log" / "backtest" / "low_level"),
            )

        # 2. åˆå§‹åŒ–å¼•æ“
        engine = BacktestEngine(
            BacktestEngineConfig(
                trader_id=TraderId("BACKTESTER-001"),
                logging=logging_config,
                risk_engine=RiskEngineConfig(bypass=False),
            )
        )

        # 3. é…ç½®äº¤æ˜“æ‰€
        venue_name = cfg.instrument.venue_name if cfg.instrument else "BINANCE"
        engine.add_venue(
            venue=Venue(venue_name),
            oms_type=OmsType.NETTING,
            book_type=BookType.L1_MBP,
            account_type=AccountType.MARGIN,
            base_currency=USDT,
            starting_balances=cfg.initial_balances,
            trade_execution=True,
            fee_model=MakerTakerFeeModel(),
        )

        # 4. åŠ è½½æ ‡çš„å®šä¹‰
        loaded_instruments = {}
        total_feeds = len(cfg.data_feeds)

        for inst_cfg in cfg.instruments:
            inst_path = inst_cfg.get_json_path()
            if not inst_path.exists():
                raise InstrumentLoadError(f"Instrument path not found: {inst_path}", inst_cfg.instrument_id)

            try:
                inst = load_instrument(inst_path)
                engine.add_instrument(inst)
                loaded_instruments[str(inst.id)] = inst
                logger.info(f"âœ… Loaded instrument: {inst.id}")
            except Exception as e:
                raise InstrumentLoadError(f"Failed to load instrument {inst_cfg.instrument_id}: {e}",
                                        inst_cfg.instrument_id, e)

        # 5. åŠ è½½å›æµ‹æ•°æ®
        all_feeds = {}  # (instrument_id, label) -> bar_type_str
        for feed_idx, data_cfg in enumerate(cfg.data_feeds, 1):
            sys.stdout.write(f"\rğŸ“– [{feed_idx}/{total_feeds}] Loading: {data_cfg.csv_file_name}")
            sys.stdout.flush()

            try:
                bt = _load_data_for_feed(engine, base_dir, cfg, data_cfg, loaded_instruments)
                if bt:
                    inst_id = data_cfg.instrument_id or str(cfg.instrument.instrument_id)
                    all_feeds[(inst_id, data_cfg.label)] = str(bt)
            except DataLoadError as e:
                logger.error(f"\nâŒ Failed to load {data_cfg.csv_file_name}: {e}")
                continue

        logger.info(f"\nâœ… Loaded {len(all_feeds)} data feeds")

        # 6. åŠ è½½è‡ªå®šä¹‰æ•°æ® (OI, Funding Rate)
        try:
            _load_custom_data_to_engine(cfg, base_dir, engine, loaded_instruments)
        except CustomDataError as e:
            logger.warning(f"âš ï¸ Custom data loading failed: {e}")

        # 7. é…ç½®ä¸æ·»åŠ ç­–ç•¥
        StrategyClass = load_strategy_class(cfg.strategy.module_path, cfg.strategy.name)
        ConfigClass = load_strategy_config_class(
            cfg.strategy.module_path, cfg.strategy.resolve_config_class()
        )

        # æå–å…¨å±€å…±äº«æ•°æ®æµ
        global_feeds = {
            label: bt for (iid, label), bt in all_feeds.items() if label == "benchmark"
        }
        strategies_count = 0

        # ä¸ºæ¯ä¸ªæ‹¥æœ‰ 'main' æ•°æ®çš„æ ‡çš„åˆ›å»ºç­–ç•¥å®ä¾‹
        for inst_id, inst in loaded_instruments.items():
            local_feeds = {
                label: bt
                for (iid, label), bt in all_feeds.items()
                if iid == inst_id and label != "benchmark"
            }

            if "main" not in local_feeds:
                continue

            # ç”Ÿæˆç­–ç•¥å‚æ•°
            strat_params = cfg.strategy.resolve_params(
                instrument_id=inst.id,
                leverage=cfg.instrument.leverage if cfg.instrument else 1,
                feed_bar_types={**local_feeds, **global_feeds},
            )

            # è¿‡æ»¤å‚æ•°å¹¶å®ä¾‹åŒ–ç­–ç•¥
            final_params = filter_strategy_params(strat_params, ConfigClass)
            strat_config = ConfigClass(**final_params)
            engine.add_strategy(StrategyClass(config=strat_config))
            strategies_count += 1

        # 8. æ‰§è¡Œå›æµ‹
        if strategies_count == 0:
            raise BacktestEngineError("No strategy instances were created. Check config and data paths.")

        logger.info(f"â³ Running engine with {strategies_count} strategy instances...")
        engine.run()
        logger.info("âœ… Backtest Complete.")

        # 9. å¤„ç†ç»“æœ
        _process_backtest_results(cfg, base_dir, engine)

        if cfg.output_html_report:
            output_dir = base_dir / "output"
            output_dir.mkdir(parents=True, exist_ok=True)
            report_path = (
                output_dir
                / f"low_{cfg.strategy.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            )
            create_tearsheet(engine=engine, output_path=str(report_path))
            logger.info(f"ğŸ“Š HTML Report generated: {report_path}")

        # 10. æ¸…ç†èµ„æº
        gc.collect()
        engine.reset()
        engine.dispose()
        logger.info("ğŸ§¹ Engine resources cleaned up")

    except (InstrumentLoadError, DataLoadError, CustomDataError) as e:
        logger.error(f"âŒ Backtest failed: {e}")
        raise
    except Exception as e:
        raise BacktestEngineError(f"Unexpected error during backtest: {e}", e)
