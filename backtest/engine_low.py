import gc
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

logger = logging.getLogger(__name__)
from nautilus_trader.analysis.tearsheet import create_tearsheet
from nautilus_trader.backtest.config import BacktestEngineConfig
from nautilus_trader.backtest.engine import BacktestEngine
from nautilus_trader.backtest.models.fee import MakerTakerFeeModel
from nautilus_trader.common.config import LoggingConfig
from nautilus_trader.config import RiskEngineConfig
from nautilus_trader.model import BarType, TraderId
from nautilus_trader.model.currencies import USDT
from nautilus_trader.model.enums import (
    AccountType,
    BookType,
    OmsType,
)
from nautilus_trader.model.identifiers import Venue
from nautilus_trader.model.instruments import Instrument
from nautilus_trader.persistence.wranglers import BarDataWrangler
from pandas import DataFrame

from backtest.exceptions import (
    BacktestEngineError,
    CustomDataError,
    DataLoadError,
    InstrumentLoadError,
)
from core.schemas import BacktestConfig, DataConfig
from strategy.core.loader import (
    filter_strategy_params,
    load_strategy_class,
    load_strategy_config_class,
)
from utils.data_management.data_loader import load_ohlcv_csv
from utils.instrument_loader import load_instrument
from utils.oi_funding_adapter import OIFundingDataLoader


def _load_data_for_feed(
    engine: BacktestEngine,
    base_dir: Path,
    cfg: BacktestConfig,
    data_cfg: DataConfig,
    loaded_instruments: Dict[str, Instrument],
) -> Optional[BarType]:
    """
    åŠ è½½ CSV æ•°æ®å¹¶æ³¨å…¥å›æµ‹å¼•æ“ (Low-Level Engine é£æ ¼)

    Args:
        engine: BacktestEngine å®ä¾‹
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        cfg: å›æµ‹é…ç½®
        data_cfg: æ•°æ®é…ç½®
        loaded_instruments: å·²åŠ è½½çš„æ ‡çš„æ˜ å°„

    Returns:
        Optional[BarType]: æˆåŠŸåŠ è½½åˆ™è¿”å› BarTypeï¼Œå¦åˆ™è¿”å› None

    Raises:
        DataLoadError: å½“æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    # ç¡®å®šå…³è”çš„ Instrument ID
    inst_id_str = data_cfg.instrument_id or str(cfg.instrument.instrument_id)
    inst = loaded_instruments.get(inst_id_str)
    if not inst:
        raise DataLoadError(f"Instrument {inst_id_str} not found for feed {data_cfg.csv_file_name}")

    feed_bar_type_str = f"{inst.id}-{data_cfg.bar_type_str}"
    feed_bar_type = BarType.from_str(feed_bar_type_str)

    csv_path = data_cfg.full_path
    if not csv_path.exists():
        raise DataLoadError(f"CSV file not found: {csv_path}", str(csv_path))

    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®åŠ è½½å™¨ (æ™ºèƒ½æ—¶é—´åˆ—æ£€æµ‹ + ä¼˜åŒ–åŠ è½½)
        df: DataFrame = load_ohlcv_csv(
            csv_path=csv_path,
            start_date=cfg.start_date,
            end_date=cfg.end_date,
        )

        if len(df) == 0:
            raise DataLoadError(f"No data available in range for {data_cfg.csv_file_name}", str(csv_path))

        # ä½¿ç”¨ Wrangler è½¬æ¢å¹¶æ³¨å…¥å¼•æ“
        wrangler = BarDataWrangler(feed_bar_type, inst)
        bars = wrangler.process(df)
        engine.add_data(bars)

        logger.info(f"âœ… Loaded {len(bars)} bars for {inst.id} ({data_cfg.label})")
        return feed_bar_type

    except Exception as e:
        if isinstance(e, DataLoadError):
            raise
        raise DataLoadError(f"Error loading {data_cfg.csv_file_name}: {e}", str(csv_path), e)


def _load_custom_data_to_engine(
    cfg: BacktestConfig,
    base_dir: Path,
    engine: BacktestEngine,
    loaded_instruments: Dict[str, Instrument],
) -> int:
    """
    åŠ è½½è‡ªå®šä¹‰æ•°æ®(OI, Funding Rate)åˆ°å›æµ‹å¼•æ“ (Low-Level Engine é£æ ¼)

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        engine: BacktestEngine å®ä¾‹
        loaded_instruments: å·²åŠ è½½çš„æ ‡çš„æ˜ å°„

    Returns:
        int: åŠ è½½çš„æ•°æ®ç‚¹æ€»æ•°

    Raises:
        CustomDataError: å½“è‡ªå®šä¹‰æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    if not (cfg.start_date and cfg.end_date):
        logger.warning("âš ï¸ No date range specified, skipping custom data loading")
        return 0

    logger.info("ğŸ“Š Loading custom data (OI, Funding Rate)...")

    try:
        from utils.oi_funding_adapter import merge_custom_data_with_bars

        data_dir = base_dir / "data" / "raw"
        total_loaded = 0

        for inst_id_str, inst in loaded_instruments.items():
            instrument_id = inst.id
            symbol = str(instrument_id.symbol).split("-")[0]  # BTCUSDT-PERP -> BTCUSDT
            symbol_dir = data_dir / symbol

            if not symbol_dir.exists():
                continue

            # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
            oi_files = list(symbol_dir.glob("*-oi-1h-*.csv"))
            funding_files = list(symbol_dir.glob("*-funding-*.csv"))

            oi_data_list = []
            funding_data_list = []

            # åŠ è½½OIæ•°æ®
            if oi_files:
                loader = OIFundingDataLoader(base_dir)
                for oi_file in oi_files:
                    oi_data_list.extend(loader.load_oi_data(
                        symbol=symbol,
                        instrument_id=instrument_id,
                        start_date=cfg.start_date,
                        end_date=cfg.end_date,
                        exchange=cfg.instrument.venue_name.lower() if cfg.instrument else "binance"
                    ))

            # åŠ è½½Funding Rateæ•°æ®
            if funding_files:
                loader = OIFundingDataLoader(base_dir)
                for funding_file in funding_files:
                    funding_data_list.extend(loader.load_funding_data(
                        symbol=symbol,
                        instrument_id=instrument_id,
                        start_date=cfg.start_date,
                        end_date=cfg.end_date,
                        exchange=cfg.instrument.venue_name.lower() if cfg.instrument else "binance"
                    ))

            # åˆå¹¶å¹¶æ·»åŠ åˆ°å¼•æ“
            if oi_data_list or funding_data_list:
                merged_data = merge_custom_data_with_bars(oi_data_list, funding_data_list)
                engine.add_data(merged_data)
                total_loaded += len(merged_data)
                logger.info(f"   âœ… Added {len(merged_data)} custom data points for {symbol}")

        logger.info(f"âœ… Total custom data loaded: {total_loaded} points")
        return total_loaded

    except Exception as e:
        raise CustomDataError(f"Custom data loading failed: {e}", cause=e)




def _process_backtest_results(
    cfg: BacktestConfig,
    base_dir: Path,
    engine: BacktestEngine,
) -> None:
    """
    å¤„ç†å›æµ‹ç»“æœ (Low-Level Engine é£æ ¼)

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•
        engine: BacktestEngine å®ä¾‹
    """
    try:
        # æå–ç­–ç•¥é…ç½®
        strategy_params = cfg.strategy.params
        if hasattr(strategy_params, "model_dump"):
            strategy_config = strategy_params.model_dump()
        elif hasattr(strategy_params, "dict"):
            strategy_config = strategy_params.dict()
        elif isinstance(strategy_params, dict):
            strategy_config = strategy_params
        else:
            strategy_config = {}

        # è·å–å›æµ‹ç»Ÿè®¡æ•°æ® - ä» trader æŠ¥å‘Šä¸­è®¡ç®—
        venue = Venue(cfg.instrument.venue_name) if cfg.instrument else Venue("BINANCE")

        # è·å–è®¢å•å’ŒæŒä»“ç»Ÿè®¡
        orders_report = engine.trader.generate_order_fills_report()
        positions_report = engine.trader.generate_positions_report()
        total_orders = len(orders_report) if orders_report is not None and hasattr(orders_report, '__len__') else 0
        total_positions = len(positions_report) if positions_report is not None and hasattr(positions_report, '__len__') else 0

        # åˆå§‹åŒ–ç»Ÿè®¡å­—å…¸
        stats_pnls = {}
        stats_returns = {}

        # ä»æŒä»“æŠ¥å‘Šä¸­è®¡ç®— PnL ç»Ÿè®¡
        try:
            if positions_report is not None and hasattr(positions_report, 'empty') and not positions_report.empty:
                # æ£€æŸ¥å¯ç”¨çš„åˆ—
                logger.debug(f"æŒä»“æŠ¥å‘Šåˆ—: {positions_report.columns.tolist()}")

                # å°è¯•å¤šä¸ªå¯èƒ½çš„ PnL åˆ—å
                pnl_column = None
                for col in ['realized_pnl', 'pnl', 'realized_return', 'return']:
                    if col in positions_report.columns:
                        pnl_column = col
                        break

                if pnl_column:
                    realized_pnls = positions_report[pnl_column].dropna()

                    if len(realized_pnls) > 0:
                        winners = realized_pnls[realized_pnls > 0]
                        losers = realized_pnls[realized_pnls < 0]

                        total_pnl = float(realized_pnls.sum())

                        stats_pnls['USDT'] = {
                            'PnL (total)': total_pnl,
                            'PnL% (total)': total_pnl,
                            'Max Winner': float(winners.max()) if len(winners) > 0 else None,
                            'Avg Winner': float(winners.mean()) if len(winners) > 0 else None,
                            'Min Winner': float(winners.min()) if len(winners) > 0 else None,
                            'Min Loser': float(losers.min()) if len(losers) > 0 else None,
                            'Avg Loser': float(losers.mean()) if len(losers) > 0 else None,
                            'Max Loser': float(losers.max()) if len(losers) > 0 else None,
                            'Expectancy': float(realized_pnls.mean()) if len(realized_pnls) > 0 else None,
                            'Win Rate': float(len(winners) / len(realized_pnls)) if len(realized_pnls) > 0 else None,
                        }

                        # è®¡ç®—æ”¶ç›Šç‡ç»Ÿè®¡
                        if len(realized_pnls) > 1:
                            import numpy as np
                            returns = realized_pnls.values

                            # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
                            avg_return = float(np.mean(returns))
                            std_return = float(np.std(returns))

                            # è®¡ç®—å¤æ™®æ¯”ç‡
                            sharpe = float(avg_return / std_return * np.sqrt(252)) if std_return > 0 else 0

                            # è®¡ç®—ç´¢æè¯ºæ¯”ç‡
                            downside_returns = returns[returns < 0]
                            downside_std = float(np.std(downside_returns)) if len(downside_returns) > 0 else 0
                            sortino = float(avg_return / downside_std * np.sqrt(252)) if downside_std > 0 else 0

                            # è®¡ç®—ç›ˆäºæ¯”
                            avg_win = float(winners.mean()) if len(winners) > 0 else 0
                            avg_loss = abs(float(losers.mean())) if len(losers) > 0 else 0
                            profit_factor = float(avg_win / avg_loss) if avg_loss > 0 else 0

                            stats_returns = {
                                'Returns Volatility (252 days)': std_return * np.sqrt(252),
                                'Average (Return)': avg_return,
                                'Average Loss (Return)': float(losers.mean()) if len(losers) > 0 else None,
                                'Average Win (Return)': avg_win,
                                'Sharpe Ratio (252 days)': sharpe,
                                'Sortino Ratio (252 days)': sortino,
                                'Profit Factor': profit_factor,
                                'Risk Return Ratio': float(std_return / abs(avg_return)) if avg_return != 0 else None,
                            }
                else:
                    logger.warning(f"æŒä»“æŠ¥å‘Šä¸­æœªæ‰¾åˆ° PnL åˆ—ï¼Œå¯ç”¨åˆ—: {positions_report.columns.tolist()}")
        except Exception as e:
            logger.warning(f"è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡æ—¶å‡ºé”™: {e}")

        # æ„å»ºå®Œæ•´ç»“æœå­—å…¸
        result_dict = {
            "meta": {
                "strategy_name": cfg.strategy.name,
                "timestamp": datetime.now().isoformat(),
                "engine_type": "low_level",
            },
            "summary": {
                "start_date": cfg.start_date,
                "end_date": cfg.end_date,
                "initial_balances": [str(balance) for balance in cfg.initial_balances],
                "total_orders": total_orders,
                "total_positions": total_positions,
            },
            "pnl": {},
            "returns": {},
            "strategy_config": strategy_config,
            "backtest_config": {
                "start_date": str(cfg.start_date),
                "end_date": str(cfg.end_date),
                "initial_balances": [str(b) for b in cfg.initial_balances],
            },
            "performance": {
                "total_orders": total_orders,
                "total_positions": total_positions,
            }
        }

        # å¤„ç† PnL æŒ‡æ ‡
        if stats_pnls is not None:
            for currency, metrics in stats_pnls.items():
                result_dict["pnl"][str(currency)] = {
                    str(k): v if v == v else None
                    for k, v in metrics.items()
                }

        # å¤„ç†æ”¶ç›Šç‡æŒ‡æ ‡ - ä½¿ç”¨ generate_returns_report è·å–ç»Ÿè®¡æ•°æ®
        try:
            returns_stats = engine.trader.generate_returns_report()
            if returns_stats:
                for key, val in returns_stats.items():
                    result_dict["returns"][str(key)] = val if val == val else None
        except Exception:
            pass

        # ä¿å­˜ JSON ç»“æœ
        result_dir = base_dir / "output" / "backtest" / "result"
        result_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"{cfg.strategy.name}_{timestamp}.json"
        filepath = result_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(result_dict, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"ğŸ“ Results saved to: {filepath}")

    except Exception as e:
        logger.warning(f"âš ï¸ Error saving results: {e}")


def run_low_level(cfg: BacktestConfig, base_dir: Path):
    """
    è¿è¡Œä½çº§å¼•æ“å›æµ‹ (Low-level Engine)

    ä¿æŒ BacktestEngine ç›´æ¥ API çš„ç®€æ´ç‰¹æ€§ï¼Œä½†å¢å¼ºé”™è¯¯å¤„ç†å’ŒåŠŸèƒ½å®Œæ•´æ€§ã€‚

    Args:
        cfg: å›æµ‹é…ç½®
        base_dir: é¡¹ç›®åŸºç¡€ç›®å½•

    Raises:
        BacktestEngineError: å½“å›æµ‹æ‰§è¡Œå¤±è´¥æ—¶
        InstrumentLoadError: å½“æ ‡çš„åŠ è½½å¤±è´¥æ—¶
        DataLoadError: å½“æ•°æ®åŠ è½½å¤±è´¥æ—¶
    """
    logger.info(f"ğŸš€ Starting Low-Level Backtest: {cfg.strategy.name}")

    try:
        # 1. é…ç½®æ—¥å¿—ç³»ç»Ÿ
        logging_config = None
        if cfg.logging:
            logging_config = LoggingConfig(
                log_level=cfg.logging.log_level,
                log_level_file=cfg.logging.log_level_file,
                log_directory=str(base_dir / "log" / "backtest" / "low_level"),
            )

        # 2. åˆå§‹åŒ–å¼•æ“
        engine = BacktestEngine(
            BacktestEngineConfig(
                trader_id=TraderId("BACKTESTER-001"),
                logging=logging_config,
                risk_engine=RiskEngineConfig(bypass=False),
            )
        )

        # 3. é…ç½®äº¤æ˜“æ‰€
        venue_name = cfg.instrument.venue_name if cfg.instrument else "BINANCE"

        # ä»ç­–ç•¥é…ç½®ä¸­è¯»å– oms_type
        oms_type_str = getattr(cfg.strategy_config, 'oms_type', 'HEDGING')
        oms_type = OmsType.HEDGING if oms_type_str == 'HEDGING' else OmsType.NETTING

        engine.add_venue(
            venue=Venue(venue_name),
            oms_type=oms_type,
            book_type=BookType.L1_MBP,
            account_type=AccountType.MARGIN,
            base_currency=USDT,
            starting_balances=cfg.initial_balances,
            trade_execution=True,
            fee_model=MakerTakerFeeModel(),
        )

        # 4. åŠ è½½æ ‡çš„å®šä¹‰
        loaded_instruments = {}
        total_feeds = len(cfg.data_feeds)

        for inst_cfg in cfg.instruments:
            inst_path = inst_cfg.get_json_path()
            if not inst_path.exists():
                raise InstrumentLoadError(f"Instrument path not found: {inst_path}", inst_cfg.instrument_id)

            try:
                inst = load_instrument(inst_path)
                engine.add_instrument(inst)
                loaded_instruments[str(inst.id)] = inst
                logger.info(f"âœ… Loaded instrument: {inst.id}")
            except Exception as e:
                raise InstrumentLoadError(f"Failed to load instrument {inst_cfg.instrument_id}: {e}",
                                        inst_cfg.instrument_id, e)

        # 5. åŠ è½½å›æµ‹æ•°æ®
        all_feeds = {}  # (instrument_id, label) -> bar_type_str
        for feed_idx, data_cfg in enumerate(cfg.data_feeds, 1):
            sys.stdout.write(f"\rğŸ“– [{feed_idx}/{total_feeds}] Loading: {data_cfg.csv_file_name}")
            sys.stdout.flush()

            try:
                bt = _load_data_for_feed(engine, base_dir, cfg, data_cfg, loaded_instruments)
                if bt:
                    inst_id = data_cfg.instrument_id or str(cfg.instrument.instrument_id)
                    all_feeds[(inst_id, data_cfg.label)] = str(bt)
            except DataLoadError as e:
                logger.error(f"\nâŒ Failed to load {data_cfg.csv_file_name}: {e}")
                continue

        logger.info(f"\nâœ… Loaded {len(all_feeds)} data feeds")

        # 6. åŠ è½½è‡ªå®šä¹‰æ•°æ® (OI, Funding Rate)
        try:
            _load_custom_data_to_engine(cfg, base_dir, engine, loaded_instruments)
        except CustomDataError as e:
            logger.warning(f"âš ï¸ Custom data loading failed: {e}")

        # 7. é…ç½®ä¸æ·»åŠ ç­–ç•¥
        StrategyClass = load_strategy_class(cfg.strategy.module_path, cfg.strategy.name)
        ConfigClass = load_strategy_config_class(
            cfg.strategy.module_path, cfg.strategy.resolve_config_class()
        )

        # æå–å…¨å±€å…±äº«æ•°æ®æµ
        global_feeds = {
            label: bt for (iid, label), bt in all_feeds.items() if label == "benchmark"
        }
        strategies_count = 0

        # ä¸ºæ¯ä¸ªæ‹¥æœ‰ 'main' æ•°æ®çš„æ ‡çš„åˆ›å»ºç­–ç•¥å®ä¾‹
        for inst_id, inst in loaded_instruments.items():
            local_feeds = {
                label: bt
                for (iid, label), bt in all_feeds.items()
                if iid == inst_id and label != "benchmark"
            }

            if "main" not in local_feeds:
                continue

            # ç”Ÿæˆç­–ç•¥å‚æ•°
            strat_params = cfg.strategy.resolve_params(
                instrument_id=inst.id,
                leverage=cfg.instrument.leverage if cfg.instrument else 1,
                feed_bar_types={**local_feeds, **global_feeds},
            )

            # è¿‡æ»¤å‚æ•°å¹¶å®ä¾‹åŒ–ç­–ç•¥
            final_params = filter_strategy_params(strat_params, ConfigClass)
            strat_config = ConfigClass(**final_params)
            engine.add_strategy(StrategyClass(config=strat_config))
            strategies_count += 1

        # 8. æ‰§è¡Œå›æµ‹
        if strategies_count == 0:
            raise BacktestEngineError("No strategy instances were created. Check config and data paths.")

        logger.info(f"â³ Running engine with {strategies_count} strategy instances...")
        engine.run()
        logger.info("âœ… Backtest Complete.")

        # 9. å¤„ç†ç»“æœ
        _process_backtest_results(cfg, base_dir, engine)

        if cfg.output_html_report:
            output_dir = base_dir / "output"
            output_dir.mkdir(parents=True, exist_ok=True)
            report_path = (
                output_dir
                / f"low_{cfg.strategy.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            )
            create_tearsheet(engine=engine, output_path=str(report_path))
            logger.info(f"ğŸ“Š HTML Report generated: {report_path}")

        # 10. æ¸…ç†èµ„æº
        gc.collect()
        engine.reset()
        engine.dispose()
        logger.info("ğŸ§¹ Engine resources cleaned up")

    except (InstrumentLoadError, DataLoadError, CustomDataError) as e:
        logger.error(f"âŒ Backtest failed: {e}")
        raise
    except Exception as e:
        raise BacktestEngineError(f"Unexpected error during backtest: {e}", e)
