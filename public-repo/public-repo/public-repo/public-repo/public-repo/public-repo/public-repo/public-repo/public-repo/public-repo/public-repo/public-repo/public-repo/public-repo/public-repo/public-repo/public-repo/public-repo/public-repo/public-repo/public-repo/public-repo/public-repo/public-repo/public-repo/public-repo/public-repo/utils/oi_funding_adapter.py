"""
OI å’Œ Funding Rate æ•°æ®é€‚é…å™¨

ç”¨äºåœ¨ NautilusTrader å›æµ‹å¼•æ“ä¸­åŠ è½½å’Œå¤„ç† Open Interest å’Œ Funding Rate æ•°æ®ã€‚
å°† CSV æ ¼å¼çš„åŸå§‹æ•°æ®è½¬æ¢ä¸º NautilusTrader è‡ªå®šä¹‰æ•°æ®ç±»å‹ã€‚
"""

import logging
from decimal import Decimal
from pathlib import Path
from typing import List, Optional

import pandas as pd
from nautilus_trader.core.nautilus_pyo3 import millis_to_nanos
from nautilus_trader.model.identifiers import InstrumentId

from utils.custom_data import FundingRateData, OpenInterestData

logger = logging.getLogger(__name__)


class OIFundingDataLoader:
    """
    OI å’Œ Funding Rate æ•°æ®åŠ è½½å™¨

    ä» CSV æ–‡ä»¶è¯»å–æ•°æ®å¹¶è½¬æ¢ä¸º NautilusTrader è‡ªå®šä¹‰æ•°æ®ç±»å‹
    """

    def __init__(self, base_dir: Path):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

        Parameters
        ----------
        base_dir : Path
            æ•°æ®æ–‡ä»¶çš„åŸºç¡€ç›®å½•ï¼ˆé€šå¸¸æ˜¯é¡¹ç›®æ ¹ç›®å½•ï¼‰
        """
        self.base_dir = base_dir
        self.data_dir = base_dir / "data" / "raw"

    def _find_available_oi_files(self, symbol: str, exchange: str = "binance") -> list:
        """æŸ¥æ‰¾å¯ç”¨çš„ OI æ•°æ®æ–‡ä»¶"""
        safe_symbol = symbol.replace("/", "")
        symbol_dir = self.data_dir / safe_symbol

        if not symbol_dir.exists():
            return []

        oi_files = list(symbol_dir.glob(f"{exchange}-{safe_symbol}-oi-*.csv"))
        return sorted(oi_files)

    def _build_oi_file_path(
        self, symbol: str, exchange: str, period: str, start_date: str, end_date: str
    ) -> Path:
        """æ„å»ºOIæ•°æ®æ–‡ä»¶è·¯å¾„"""
        safe_symbol = symbol.replace("/", "")
        filename = f"{exchange}-{safe_symbol}-oi-{period}-{start_date}_{end_date}.csv"
        return self.data_dir / safe_symbol / filename

    def _log_missing_oi_file(self, file_path: Path, symbol: str, exchange: str):
        """è®°å½•ç¼ºå¤±çš„OIæ–‡ä»¶ä¿¡æ¯"""
        logger.warning(f"âš ï¸  OI data file not found: {file_path}")

        available_files = self._find_available_oi_files(symbol, exchange)
        if available_files:
            logger.info(f"ğŸ’¡ Found {len(available_files)} available OI file(s):")
            for f in available_files[:5]:
                logger.info(f"   - {f.name}")
            if len(available_files) > 5:
                logger.info(f"   ... and {len(available_files) - 5} more")
        else:
            safe_symbol = symbol.replace("/", "")
            logger.error(f"âŒ No OI data files found for {symbol} in {self.data_dir / safe_symbol}")

    def _validate_oi_dataframe(self, df: pd.DataFrame, file_path: Path) -> bool:
        """éªŒè¯OIæ•°æ®æ ¼å¼"""
        if "timestamp" not in df.columns or "open_interest" not in df.columns:
            logger.warning(f"Warning: Invalid OI data format in {file_path}")
            return False
        return True

    def _convert_row_to_oi_data(self, row, instrument_id: InstrumentId) -> OpenInterestData:
        """å°†DataFrameè¡Œè½¬æ¢ä¸ºOpenInterestDataå¯¹è±¡"""
        ts_ms = int(row["timestamp"])
        ts_event = millis_to_nanos(ts_ms)
        ts_init = ts_event
        oi = Decimal(str(row["open_interest"]))

        return OpenInterestData(
            instrument_id=instrument_id,
            open_interest=oi,
            ts_event=ts_event,
            ts_init=ts_init,
        )

    def load_oi_data(
        self,
        symbol: str,
        instrument_id: InstrumentId,
        start_date: str,
        end_date: str,
        exchange: str = "binance",
        period: str = "1h",
    ) -> List[OpenInterestData]:
        """
        åŠ è½½ Open Interest æ•°æ®

        Parameters
        ----------
        symbol : str
            äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ "BTCUSDT"ï¼‰
        instrument_id : InstrumentId
            NautilusTrader åˆçº¦æ ‡è¯†ç¬¦
        start_date : str
            å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        end_date : str
            ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        exchange : str
            äº¤æ˜“æ‰€åç§°ï¼ˆé»˜è®¤ "binance"ï¼‰
        period : str
            æ•°æ®å‘¨æœŸï¼ˆé»˜è®¤ "1h"ï¼‰

        Returns
        -------
        List[OpenInterestData]
            OI æ•°æ®åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº
        """
        file_path = self._build_oi_file_path(symbol, exchange, period, start_date, end_date)

        if not file_path.exists():
            self._log_missing_oi_file(file_path, symbol, exchange)
            return []

        try:
            df = pd.read_csv(file_path)

            if not self._validate_oi_dataframe(df, file_path):
                return []

            oi_data_list = [
                self._convert_row_to_oi_data(row, instrument_id) for _, row in df.iterrows()
            ]

            logger.info(f"âœ… Loaded {len(oi_data_list)} OI data points for {symbol}")
            return oi_data_list

        except Exception as e:
            logger.error(f"Error loading OI data from {file_path}: {e}")
            return []

    def _find_available_funding_files(self, symbol: str, exchange: str = "binance") -> list:
        """æŸ¥æ‰¾å¯ç”¨çš„ Funding Rate æ•°æ®æ–‡ä»¶"""
        safe_symbol = symbol.replace("/", "")
        symbol_dir = self.data_dir / safe_symbol

        if not symbol_dir.exists():
            return []

        funding_files = list(symbol_dir.glob(f"{exchange}-{safe_symbol}-funding-*.csv"))
        return sorted(funding_files)

    def _build_funding_file_path(
        self, symbol: str, exchange: str, start_date: str, end_date: str
    ) -> Path:
        """æ„å»ºFundingæ•°æ®æ–‡ä»¶è·¯å¾„"""
        safe_symbol = symbol.replace("/", "")
        filename = f"{exchange}-{safe_symbol}-funding-{start_date}_{end_date}.csv"
        return self.data_dir / safe_symbol / filename

    def _log_file_not_found(self, file_path: Path, symbol: str, exchange: str) -> None:
        """è®°å½•æ–‡ä»¶æœªæ‰¾åˆ°çš„è­¦å‘Šä¿¡æ¯"""
        logger.warning(f"âš ï¸  Funding data file not found: {file_path}")

        # æŸ¥æ‰¾å¯ç”¨çš„æ›¿ä»£æ–‡ä»¶
        available_files = self._find_available_funding_files(symbol, exchange)
        if available_files:
            logger.info(f"ğŸ’¡ Found {len(available_files)} available Funding file(s):")
            for f in available_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                logger.info(f"   - {f.name}")
            if len(available_files) > 5:
                logger.info(f"   ... and {len(available_files) - 5} more")
        else:
            safe_symbol = symbol.replace("/", "")
            logger.error(
                f"âŒ No Funding data files found for {symbol} in {self.data_dir / safe_symbol}"
            )

    def _validate_funding_dataframe(self, df: pd.DataFrame, file_path: Path) -> bool:
        """éªŒè¯Fundingæ•°æ®DataFrameæ ¼å¼"""
        if "timestamp" not in df.columns or "funding_rate" not in df.columns:
            logger.warning(f"Warning: Invalid funding data format in {file_path}")
            return False
        return True

    def _parse_next_funding_time(self, row: pd.Series, df: pd.DataFrame) -> Optional[int]:
        """è§£æä¸‹æ¬¡èµ„é‡‘è´¹ç‡ç»“ç®—æ—¶é—´"""
        if "next_funding_time" in df.columns and pd.notna(row["next_funding_time"]):
            return millis_to_nanos(int(row["next_funding_time"]))
        return None

    def _convert_row_to_funding_data(
        self, row: pd.Series, df: pd.DataFrame, instrument_id: InstrumentId
    ) -> FundingRateData:
        """å°†DataFrameè¡Œè½¬æ¢ä¸ºFundingRateDataå¯¹è±¡"""
        ts_ms = int(row["timestamp"])
        ts_event = millis_to_nanos(ts_ms)
        ts_init = ts_event

        funding_rate = Decimal(str(row["funding_rate"]))
        next_funding_time = self._parse_next_funding_time(row, df)

        return FundingRateData(
            instrument_id=instrument_id,
            funding_rate=funding_rate,
            next_funding_time=next_funding_time,
            ts_event=ts_event,
            ts_init=ts_init,
        )

    def _parse_funding_dataframe(
        self, df: pd.DataFrame, instrument_id: InstrumentId
    ) -> List[FundingRateData]:
        """è§£æDataFrameä¸ºFundingRateDataåˆ—è¡¨"""
        funding_data_list = []
        for _, row in df.iterrows():
            funding_data = self._convert_row_to_funding_data(row, df, instrument_id)
            funding_data_list.append(funding_data)
        return funding_data_list

    def load_funding_data(
        self,
        symbol: str,
        instrument_id: InstrumentId,
        start_date: str,
        end_date: str,
        exchange: str = "binance",
    ) -> List[FundingRateData]:
        """
        åŠ è½½ Funding Rate æ•°æ®

        Parameters
        ----------
        symbol : str
            äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ "BTCUSDT"ï¼‰
        instrument_id : InstrumentId
            NautilusTrader åˆçº¦æ ‡è¯†ç¬¦
        start_date : str
            å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        end_date : str
            ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
        exchange : str
            äº¤æ˜“æ‰€åç§°ï¼ˆé»˜è®¤ "binance"ï¼‰

        Returns
        -------
        List[FundingRateData]
            Funding Rate æ•°æ®åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº
        """
        file_path = self._build_funding_file_path(symbol, exchange, start_date, end_date)

        if not file_path.exists():
            self._log_file_not_found(file_path, symbol, exchange)
            return []

        try:
            df = pd.read_csv(file_path)

            if not self._validate_funding_dataframe(df, file_path):
                return []

            funding_data_list = self._parse_funding_dataframe(df, instrument_id)

            logger.info(f"Loaded {len(funding_data_list)} Funding Rate data points for {symbol}")
            return funding_data_list

        except Exception as e:
            logger.error(f"Error loading Funding data from {file_path}: {e}")
            return []

    def load_all_custom_data(
        self,
        symbol: str,
        instrument_id: InstrumentId,
        start_date: str,
        end_date: str,
        exchange: str = "binance",
        oi_period: str = "1h",
    ) -> dict:
        """
        ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰è‡ªå®šä¹‰æ•°æ®ï¼ˆOI + Funding Rateï¼‰

        Parameters
        ----------
        symbol : str
            äº¤æ˜“å¯¹ç¬¦å·
        instrument_id : InstrumentId
            NautilusTrader åˆçº¦æ ‡è¯†ç¬¦
        start_date : str
            å¼€å§‹æ—¥æœŸ
        end_date : str
            ç»“æŸæ—¥æœŸ
        exchange : str
            äº¤æ˜“æ‰€åç§°
        oi_period : str
            OI æ•°æ®å‘¨æœŸ

        Returns
        -------
        dict
            åŒ…å« 'oi' å’Œ 'funding' é”®çš„å­—å…¸
        """
        oi_data = self.load_oi_data(
            symbol=symbol,
            instrument_id=instrument_id,
            start_date=start_date,
            end_date=end_date,
            exchange=exchange,
            period=oi_period,
        )

        funding_data = self.load_funding_data(
            symbol=symbol,
            instrument_id=instrument_id,
            start_date=start_date,
            end_date=end_date,
            exchange=exchange,
        )

        return {
            "oi": oi_data,
            "funding": funding_data,
        }


def merge_custom_data_with_bars(
    oi_data: List[OpenInterestData],
    funding_data: List[FundingRateData],
) -> List:
    """
    å°† OI å’Œ Funding Rate æ•°æ®åˆå¹¶æˆç»Ÿä¸€çš„æ—¶é—´åºåˆ—

    Parameters
    ----------
    oi_data : List[OpenInterestData]
        OI æ•°æ®åˆ—è¡¨
    funding_data : List[FundingRateData]
        Funding Rate æ•°æ®åˆ—è¡¨

    Returns
    -------
    List
        æŒ‰æ—¶é—´æˆ³æ’åºçš„æ··åˆæ•°æ®åˆ—è¡¨
    """
    # åˆå¹¶ä¸¤ç§æ•°æ®ç±»å‹
    all_data = []
    all_data.extend(oi_data)
    all_data.extend(funding_data)

    # æŒ‰æ—¶é—´æˆ³æ’åº
    all_data.sort(key=lambda x: x.ts_event)

    return all_data


def validate_data_alignment(
    oi_data: List[OpenInterestData],
    funding_data: List[FundingRateData],
    bar_count: int,
    tolerance_hours: int = 1,
) -> dict:
    """
    éªŒè¯è‡ªå®šä¹‰æ•°æ®ä¸ OHLCV æ•°æ®çš„å¯¹é½æƒ…å†µ

    Parameters
    ----------
    oi_data : List[OpenInterestData]
        OI æ•°æ®åˆ—è¡¨
    funding_data : List[FundingRateData]
        Funding Rate æ•°æ®åˆ—è¡¨
    bar_count : int
        OHLCV Bar æ•°é‡
    tolerance_hours : int
        æ—¶é—´å®¹å·®ï¼ˆå°æ—¶ï¼‰

    Returns
    -------
    dict
        éªŒè¯ç»“æœ
    """
    result = {
        "valid": True,
        "warnings": [],
        "oi_count": len(oi_data),
        "funding_count": len(funding_data),
        "bar_count": bar_count,
    }

    # æ£€æŸ¥ OI æ•°æ®æ•°é‡
    if len(oi_data) == 0:
        result["valid"] = False
        result["warnings"].append("No OI data available")
    elif abs(len(oi_data) - bar_count) > tolerance_hours:
        result["warnings"].append(
            f"OI data count ({len(oi_data)}) differs significantly from bar count ({bar_count})"
        )

    # æ£€æŸ¥ Funding Rate æ•°æ®æ•°é‡
    expected_funding_count = bar_count // 8  # æ¯ 8 å°æ—¶ä¸€æ¬¡
    if len(funding_data) == 0:
        result["valid"] = False
        result["warnings"].append("No Funding Rate data available")
    elif abs(len(funding_data) - expected_funding_count) > tolerance_hours:
        result["warnings"].append(
            f"Funding data count ({len(funding_data)}) differs from expected ({expected_funding_count})"
        )

    return result


def _get_supported_exchanges(preferred_exchange: str) -> list:
    """è·å–æ”¯æŒçš„äº¤æ˜“æ‰€åˆ—è¡¨"""
    if preferred_exchange == "auto":
        return ["binance", "okx"]

    if preferred_exchange in ["binance", "okx"]:
        fallback = "okx" if preferred_exchange == "binance" else "binance"
        return [preferred_exchange, fallback]

    return ["binance", "okx"]


def _process_data_task(
    data_type: str,
    symbols: set,
    exchange: str,
    start_date: str,
    end_date: str,
    period: str,
    base_dir: Path,
    max_retries: int,
    supported_exchanges: list,
) -> tuple:
    """å¤„ç†å•ä¸ªæ•°æ®è·å–ä»»åŠ¡"""
    from utils.data_management.data_manager import fetch_data_with_retry

    if not symbols:
        return 0, 0, 0, None

    symbols_list = sorted(list(symbols))
    return fetch_data_with_retry(
        data_type,
        symbols_list,
        exchange,
        start_date,
        end_date,
        period,
        base_dir,
        max_retries,
        supported_exchanges,
    )


def _update_results(
    results: dict, files: int, retries: int, fallbacks: int, error: str, file_key: str
):
    """æ›´æ–°ç»“æœç»Ÿè®¡"""
    results[file_key] += files
    results["retries"] += retries
    results["fallbacks"] += fallbacks
    if error:
        results["errors"].append(error)


def execute_oi_funding_data_fetch(
    tasks: dict, base_dir: Path, preferred_exchange: str = "auto", max_retries: int = 3
) -> dict:
    """
    æ‰§è¡Œ OI å’Œ Funding Rate æ•°æ®è·å–ï¼ˆå¸¦æ™ºèƒ½é‡è¯•å’Œé”™è¯¯æ¢å¤ï¼‰

    Parameters
    ----------
    tasks : dict
        æ•°æ®è·å–ä»»åŠ¡å­—å…¸ï¼ŒåŒ…å« oi_tasks å’Œ funding_tasks
    base_dir : Path
        é¡¹ç›®åŸºç¡€ç›®å½•
    preferred_exchange : str
        é¦–é€‰äº¤æ˜“æ‰€ï¼Œé»˜è®¤ "auto"
    max_retries : int
        æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 3

    Returns
    -------
    dict
        æ‰§è¡Œç»“æœç»Ÿè®¡
    """
    results = {"oi_files": 0, "funding_files": 0, "errors": [], "retries": 0, "fallbacks": 0}
    supported_exchanges = _get_supported_exchanges(preferred_exchange)

    # å¤„ç† OI æ•°æ®
    for (exchange, period, start_date, end_date), symbols in tasks["oi_tasks"].items():
        files, retries, fallbacks, error = _process_data_task(
            "oi",
            symbols,
            exchange,
            start_date,
            end_date,
            period,
            base_dir,
            max_retries,
            supported_exchanges,
        )
        _update_results(results, files, retries, fallbacks, error, "oi_files")

    # å¤„ç† Funding æ•°æ®
    for (exchange, start_date, end_date), symbols in tasks["funding_tasks"].items():
        files, retries, fallbacks, error = _process_data_task(
            "funding",
            symbols,
            exchange,
            start_date,
            end_date,
            "1h",
            base_dir,
            max_retries,
            supported_exchanges,
        )
        _update_results(results, files, retries, fallbacks, error, "funding_files")

    return results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from pathlib import Path

    from nautilus_trader.model.identifiers import InstrumentId

    # åˆå§‹åŒ–åŠ è½½å™¨
    base_dir = Path(__file__).parent.parent
    loader = OIFundingDataLoader(base_dir)

    # åŠ è½½æ•°æ®
    symbol = "BTCUSDT"
    instrument_id = InstrumentId.from_str("BTCUSDT.BINANCE")

    custom_data = loader.load_all_custom_data(
        symbol=symbol,
        instrument_id=instrument_id,
        start_date="2024-01-01",
        end_date="2024-12-31",
        exchange="binance",
        oi_period="1h",
    )

    logger.info("\nğŸ“Š Custom Data Summary:")
    logger.info(f"  OI Data Points: {len(custom_data['oi'])}")
    logger.info(f"  Funding Rate Data Points: {len(custom_data['funding'])}")

    # åˆå¹¶æ•°æ®
    merged = merge_custom_data_with_bars(custom_data["oi"], custom_data["funding"])
    logger.info(f"  Total Custom Data Points: {len(merged)}")
