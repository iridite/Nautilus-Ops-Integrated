"""
æ•°æ®éªŒè¯å·¥å…·æ¨¡å—

æä¾›é€šç”¨çš„æ•°æ®å¼‚å¸¸æ£€æµ‹å’ŒéªŒè¯åŠŸèƒ½ï¼Œå¯è¢«å¤šä¸ªç­–ç•¥å¤ç”¨ã€‚
é€‚ç”¨äº OIã€Funding Rateã€ä»·æ ¼ç­‰å¸‚åœºæ•°æ®çš„å¼‚å¸¸æ£€æµ‹ã€‚
"""

"""æ•°æ®éªŒè¯æ¨¡å— - æ£€æŸ¥å›æµ‹æ‰€éœ€æ•°æ®æ˜¯å¦å®Œæ•´"""

import logging
from decimal import Decimal
from pathlib import Path
from typing import Optional

import pandas as pd

from backtest.tui_manager import get_tui, is_tui_enabled

logger = logging.getLogger(__name__)


class DataValidator:
    """
    æ•°æ®éªŒè¯å™¨

    åŠŸèƒ½ï¼š
    - æ£€æµ‹æ•°æ®æœ‰æ•ˆæ€§ï¼ˆNaNã€Noneã€0ã€è´Ÿæ•°ï¼‰
    - æ£€æµ‹æ•°æ®å‰§çƒˆå˜åŒ–ï¼ˆæ¢æœˆã€æ•°æ®é”™è¯¯ï¼‰
    - æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆè¶…å‡ºåˆç†èŒƒå›´ï¼‰
    - æä¾›çµæ´»çš„é˜ˆå€¼é…ç½®
    """

    def __init__(
        self,
        spike_threshold: float = 0.5,
        enable_logging: bool = True,
    ):
        """
        åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨

        Parameters
        ----------
        spike_threshold : float
            æ•°æ®çªå˜é˜ˆå€¼ï¼ˆé»˜è®¤ 50%ï¼‰
        enable_logging : bool
            æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•
        """
        self.spike_threshold = spike_threshold
        self.enable_logging = enable_logging
        self._last_valid_value: Optional[Decimal] = None

    def _check_oi_validity(self, oi_value: Optional[Decimal], logger) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥OIæ•°æ®æœ‰æ•ˆæ€§"""
        if oi_value is None or oi_value <= 0:
            error_msg = f"Invalid OI data: {oi_value}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_oi_spike(self, oi_value: Decimal, logger) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥OIå‰§çƒˆå˜åŒ–"""
        if self._last_valid_value is None or self._last_valid_value <= 0:
            return True, None

        change_pct = abs(float((oi_value - self._last_valid_value) / self._last_valid_value))
        if change_pct > self.spike_threshold:
            error_msg = (
                f"OI spike detected: {change_pct:.1%} change "
                f"(from {self._last_valid_value:.0f} to {oi_value:.0f}). "
                f"Possible contract roll or data error."
            )
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def validate_oi(self, oi_value: Optional[Decimal], logger=None) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ OIï¼ˆæŒä»“é‡ï¼‰æ•°æ®

        Parameters
        ----------
        oi_value : Optional[Decimal]
            OI æ•°æ®å€¼
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        is_valid, error_msg = self._check_oi_validity(oi_value, logger)
        if not is_valid:
            return False, error_msg

        is_valid, error_msg = self._check_oi_spike(oi_value, logger)
        if not is_valid:
            return False, error_msg

        self._last_valid_value = oi_value
        return True, None

    def _check_funding_none(
        self, funding_annual: Optional[Decimal], logger
    ) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥èµ„é‡‘è´¹ç‡æ˜¯å¦ä¸ºNone"""
        if funding_annual is None:
            error_msg = "Invalid Funding Rate data: None"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_funding_abnormal(
        self, funding_annual: Decimal, max_abs_value: float, logger
    ) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥èµ„é‡‘è´¹ç‡æ˜¯å¦è¶…å‡ºæ­£å¸¸èŒƒå›´"""
        if abs(float(funding_annual)) > max_abs_value:
            error_msg = (
                f"Abnormal Funding Rate: {funding_annual:.2f}% (annual), "
                f"exceeds Â±{max_abs_value}% threshold. Possible data error."
            )
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_funding_spike(
        self, funding_annual: Decimal, spike_threshold: float, logger
    ) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥èµ„é‡‘è´¹ç‡æ˜¯å¦æœ‰å‰§çƒˆå˜åŒ–"""
        if self._last_valid_value is not None:
            change = abs(float(funding_annual - self._last_valid_value))
            if change > spike_threshold:
                error_msg = (
                    f"Funding Rate spike detected: {change:.1f}% change "
                    f"(from {self._last_valid_value:.2f}% to {funding_annual:.2f}%). "
                    f"Possible data error."
                )
                if logger and self.enable_logging:
                    logger.warning(f"âš ï¸  {error_msg}")
                return False, error_msg
        return True, None

    def validate_funding_rate(
        self,
        funding_annual: Optional[Decimal],
        max_abs_value: float = 500.0,
        spike_threshold: float = 200.0,
        logger=None,
    ) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ Funding Rateï¼ˆèµ„é‡‘è´¹ç‡ï¼‰æ•°æ®

        Parameters
        ----------
        funding_annual : Optional[Decimal]
            å¹´åŒ–èµ„é‡‘è´¹ç‡
        max_abs_value : float
            æœ€å¤§ç»å¯¹å€¼ï¼ˆé»˜è®¤ Â±500%ï¼‰
        spike_threshold : float
            çªå˜é˜ˆå€¼ï¼ˆé»˜è®¤ 200%ï¼‰
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥ 1: æ•°æ®æœ‰æ•ˆæ€§
        is_valid, error_msg = self._check_funding_none(funding_annual, logger)
        if not is_valid:
            return False, error_msg

        # æ£€æŸ¥ 2: å¼‚å¸¸å€¼æ£€æµ‹
        is_valid, error_msg = self._check_funding_abnormal(funding_annual, max_abs_value, logger)
        if not is_valid:
            return False, error_msg

        # æ£€æŸ¥ 3: å‰§çƒˆå˜åŒ–æ£€æµ‹
        is_valid, error_msg = self._check_funding_spike(funding_annual, spike_threshold, logger)
        if not is_valid:
            return False, error_msg

        # æ•°æ®é€šè¿‡éªŒè¯
        self._last_valid_value = funding_annual
        return True, None

    def _check_price_validity(self, price: Optional[Decimal], logger) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥ä»·æ ¼æœ‰æ•ˆæ€§"""
        if price is None or price <= 0:
            error_msg = f"Invalid price data: {price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_price_min_range(
        self, price: Decimal, min_price: Optional[Decimal], logger
    ) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥ä»·æ ¼æœ€å°èŒƒå›´"""
        if min_price is not None and price < min_price:
            error_msg = f"Price {price} below minimum {min_price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_price_max_range(
        self, price: Decimal, max_price: Optional[Decimal], logger
    ) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥ä»·æ ¼æœ€å¤§èŒƒå›´"""
        if max_price is not None and price > max_price:
            error_msg = f"Price {price} above maximum {max_price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg
        return True, None

    def _check_price_spike(self, price: Decimal, logger) -> tuple[bool, Optional[str]]:
        """æ£€æŸ¥ä»·æ ¼å‰§çƒˆå˜åŒ–"""
        if self._last_valid_value is not None and self._last_valid_value > 0:
            change_pct = abs(float((price - self._last_valid_value) / self._last_valid_value))
            if change_pct > self.spike_threshold:
                error_msg = (
                    f"Price spike detected: {change_pct:.1%} change "
                    f"(from {self._last_valid_value:.2f} to {price:.2f}). "
                    f"Possible data error or circuit breaker."
                )
                if logger and self.enable_logging:
                    logger.warning(f"âš ï¸  {error_msg}")
                return False, error_msg
        return True, None

    def validate_price(
        self,
        price: Optional[Decimal],
        min_price: Optional[Decimal] = None,
        max_price: Optional[Decimal] = None,
        logger=None,
    ) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ä»·æ ¼æ•°æ®

        Parameters
        ----------
        price : Optional[Decimal]
            ä»·æ ¼æ•°æ®
        min_price : Optional[Decimal]
            æœ€å°åˆç†ä»·æ ¼
        max_price : Optional[Decimal]
            æœ€å¤§åˆç†ä»·æ ¼
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥ 1: æ•°æ®æœ‰æ•ˆæ€§
        is_valid, error = self._check_price_validity(price, logger)
        if not is_valid:
            return False, error

        # æ£€æŸ¥ 2: ä»·æ ¼æœ€å°èŒƒå›´
        is_valid, error = self._check_price_min_range(price, min_price, logger)
        if not is_valid:
            return False, error

        # æ£€æŸ¥ 3: ä»·æ ¼æœ€å¤§èŒƒå›´
        is_valid, error = self._check_price_max_range(price, max_price, logger)
        if not is_valid:
            return False, error

        # æ£€æŸ¥ 4: å‰§çƒˆå˜åŒ–æ£€æµ‹
        is_valid, error = self._check_price_spike(price, logger)
        if not is_valid:
            return False, error

        # æ•°æ®é€šè¿‡éªŒè¯
        self._last_valid_value = price
        return True, None

    def reset(self):
        """é‡ç½®éªŒè¯å™¨çŠ¶æ€"""
        self._last_valid_value = None


def _check_file_exists(file_path: Path, file_type: str, logger) -> tuple[bool, Optional[str]]:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not file_path.exists():
        error_msg = f"{file_type}æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        if logger:
            logger.error(error_msg)
        return False, error_msg
    return True, None


def _detect_time_column(
    df: pd.DataFrame, file_path: Path, file_type: str, logger
) -> tuple[Optional[str], Optional[str]]:
    """æ£€æµ‹æ•°æ®æ¡†ä¸­çš„æ—¶é—´åˆ—"""
    time_cols = ["timestamp", "datetime", "time", "date"]
    for col in time_cols:
        if col in df.columns:
            return col, None

    error_msg = f"{file_type}æ•°æ®ç¼ºå°‘æ—¶é—´åˆ—: {file_path}"
    if logger:
        logger.error(error_msg)
    return None, error_msg


def _calculate_alignment_stats(
    primary_timestamps: set, secondary_timestamps: set
) -> tuple[int, int, int, float]:
    """è®¡ç®—å¯¹é½ç»Ÿè®¡ä¿¡æ¯"""
    common_timestamps = primary_timestamps & secondary_timestamps
    primary_count = len(primary_timestamps)
    secondary_count = len(secondary_timestamps)
    common_count = len(common_timestamps)
    alignment_rate = common_count / primary_count if primary_count > 0 else 0.0
    return primary_count, secondary_count, common_count, alignment_rate


def _log_alignment_info(
    logger, primary_count: int, secondary_count: int, common_count: int, alignment_rate: float
) -> None:
    """è®°å½•å¯¹é½ä¿¡æ¯"""
    if logger:
        logger.info(
            f"æ•°æ®å¯¹é½æ£€æŸ¥: "
            f"ä¸»æ ‡çš„={primary_count}æ¡, "
            f"è¾…åŠ©æ ‡çš„={secondary_count}æ¡, "
            f"å…±åŒ={common_count}æ¡, "
            f"å¯¹é½ç‡={alignment_rate:.1%}"
        )


def _check_alignment_threshold(
    alignment_rate: float,
    min_alignment_rate: float,
    primary_csv: Path,
    secondary_csv: Path,
    primary_count: int,
    secondary_count: int,
    common_count: int,
    logger,
) -> tuple[bool, Optional[str]]:
    """æ£€æŸ¥å¯¹é½ç‡æ˜¯å¦è¾¾åˆ°é˜ˆå€¼"""
    if alignment_rate < min_alignment_rate:
        error_msg = (
            f"æ•°æ®å¯¹é½ç‡è¿‡ä½: {alignment_rate:.1%} < {min_alignment_rate:.1%}\n"
            f"ä¸»æ ‡çš„: {primary_csv.name} ({primary_count}æ¡)\n"
            f"è¾…åŠ©æ ‡çš„: {secondary_csv.name} ({secondary_count}æ¡)\n"
            f"å…±åŒæ—¶é—´æˆ³: {common_count}æ¡\n"
            f"å»ºè®®: æ£€æŸ¥æ•°æ®æºæˆ–é‡æ–°ä¸‹è½½æ•°æ®"
        )
        if logger:
            logger.warning(f"âš ï¸  {error_msg}")
        return False, error_msg

    if logger:
        logger.info(f"âœ… æ•°æ®å¯¹é½éªŒè¯é€šè¿‡: {alignment_rate:.1%}")
    return True, None


def validate_multi_instrument_alignment(
    primary_csv: Path, secondary_csv: Path, min_alignment_rate: float = 0.95, logger=None
) -> tuple[bool, Optional[str]]:
    """
    éªŒè¯å¤šæ ‡çš„æ•°æ®æ—¶é—´æˆ³å¯¹é½

    ç”¨äºæ£€æŸ¥ç­–ç•¥éœ€è¦çš„å¤šä¸ªæ ‡çš„æ•°æ®æ˜¯å¦æ—¶é—´åŒæ­¥ï¼Œé˜²æ­¢æœªæ¥å‡½æ•°ã€‚
    ä¾‹å¦‚ï¼šDK_Alpha_Trendç­–ç•¥éœ€è¦ä¸»æ ‡çš„(ETH)å’ŒBTCæ•°æ®å¯¹é½ã€‚

    Parameters
    ----------
    primary_csv : Path
        ä¸»æ ‡çš„CSVæ–‡ä»¶è·¯å¾„
    secondary_csv : Path
        è¾…åŠ©æ ‡çš„CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚BTCï¼‰
    min_alignment_rate : float
        æœ€å°å¯¹é½ç‡é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰
    logger : Logger, optional
        æ—¥å¿—è®°å½•å™¨

    Returns
    -------
    tuple[bool, Optional[str]]
        (æ˜¯å¦å¯¹é½, é”™è¯¯ä¿¡æ¯)

    Examples
    --------
    >>> is_aligned, error = validate_multi_instrument_alignment(
    ...     Path("data/raw/ETHUSDT-PERP_1-DAY.csv"),
    ...     Path("data/raw/BTCUSDT-PERP_1-DAY.csv")
    ... )
    >>> if not is_aligned:
    ...     print(f"æ•°æ®å¯¹é½é—®é¢˜: {error}")
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        exists, error = _check_file_exists(primary_csv, "ä¸»æ ‡çš„", logger)
        if not exists:
            return False, error

        exists, error = _check_file_exists(secondary_csv, "è¾…åŠ©æ ‡çš„", logger)
        if not exists:
            return False, error

        # åŠ è½½æ•°æ®
        primary_df = pd.read_csv(primary_csv)
        secondary_df = pd.read_csv(secondary_csv)

        # æ£€æµ‹æ—¶é—´åˆ—
        primary_time_col, error = _detect_time_column(primary_df, primary_csv, "ä¸»æ ‡çš„", logger)
        if error:
            return False, error

        secondary_time_col, error = _detect_time_column(
            secondary_df, secondary_csv, "è¾…åŠ©æ ‡çš„", logger
        )
        if error:
            return False, error

        # æå–æ—¶é—´æˆ³é›†åˆ
        primary_timestamps = set(primary_df[primary_time_col])
        secondary_timestamps = set(secondary_df[secondary_time_col])

        # è®¡ç®—å¯¹é½ç»Ÿè®¡
        primary_count, secondary_count, common_count, alignment_rate = _calculate_alignment_stats(
            primary_timestamps, secondary_timestamps
        )

        # è®°å½•å¯¹é½ä¿¡æ¯
        _log_alignment_info(logger, primary_count, secondary_count, common_count, alignment_rate)

        # æ£€æŸ¥å¯¹é½ç‡é˜ˆå€¼
        return _check_alignment_threshold(
            alignment_rate,
            min_alignment_rate,
            primary_csv,
            secondary_csv,
            primary_count,
            secondary_count,
            common_count,
            logger,
        )

    except Exception as e:
        error_msg = f"æ•°æ®å¯¹é½éªŒè¯å¤±è´¥: {e}"
        if logger:
            logger.error(error_msg)
        return False, error_msg


def prepare_data_feeds(args, adapter, base_dir, universe_symbols: set):
    """å‡†å¤‡æ•°æ®æµï¼ˆéªŒè¯æˆ–è·å–ï¼‰"""
    from utils.data_file_checker import check_single_data_file

    from .data_manager import run_batch_data_retrieval

    if args.skip_data_check:
        tui = get_tui()
        if is_tui_enabled():
            tui.add_log("Skipping data validation", "INFO")
        else:
            logger.info("â© Skipping data validation")
        return

    tui = get_tui()
    use_tui = is_tui_enabled()

    if use_tui:
        tui.start_phase("Data Validation", total=None)
    else:
        logger.info("ğŸ“Š Data Validation")

    venue = adapter.get_venue().lower()
    start_date = adapter.get_start_date()
    end_date = adapter.get_end_date()
    timeframe = adapter.get_main_timeframe()

    # ä»ç­–ç•¥é…ç½®è·å–äº¤æ˜“å¯¹è±¡åˆ—è¡¨
    symbols_to_check = universe_symbols if universe_symbols else set(adapter._get_trading_symbols())

    if use_tui:
        tui.start_phase("Checking Data Files", total=len(symbols_to_check))

    missing_symbols = []
    for idx, symbol in enumerate(symbols_to_check, 1):
        exists, _ = check_single_data_file(
            symbol.split(":")[0], start_date, end_date, timeframe, venue, base_dir
        )
        if not exists:
            missing_symbols.append(symbol.split(":")[0])

        if use_tui:
            tui.update_progress(description=f"Checking {symbol.split(':')[0]}...")

    if missing_symbols:
        if use_tui:
            tui.add_log(f"{len(missing_symbols)} symbols need data", "INFO")
            tui.start_phase("Fetching Missing Data", total=len(missing_symbols))
        else:
            logger.info(f"ğŸ“¥ {len(missing_symbols)} symbols need data")

        run_batch_data_retrieval(missing_symbols, start_date, end_date, timeframe, venue, base_dir)
    else:
        if use_tui:
            tui.add_log("All data files present", "INFO")
        else:
            logger.info("âœ… All data files present")

    # æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½ï¼ˆå¦‚æœç­–ç•¥éœ€è¦ï¼‰
    _check_multi_instrument_alignment(adapter, base_dir, venue, timeframe)


def _check_multi_instrument_alignment(adapter, base_dir: Path, venue: str, timeframe: str):
    """æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½ï¼ˆå¦‚æœç­–ç•¥éœ€è¦ï¼‰"""
    import logging

    logger = logging.getLogger(__name__)

    try:
        # è·å–ç­–ç•¥é…ç½®
        config = adapter.build_backtest_config()
        strategy_params = (
            config.strategy.params if hasattr(config.strategy, "params") else config.strategy
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰è¾…åŠ©æ ‡çš„é…ç½®ï¼ˆå¦‚ btc_instrument_idï¼‰
        btc_instrument_id = getattr(strategy_params, "btc_instrument_id", None)
        if not btc_instrument_id:
            return  # ç­–ç•¥ä¸éœ€è¦å¤šæ ‡çš„å¯¹é½æ£€æŸ¥

        # æå–ä¸»æ ‡çš„å’ŒBTCæ ‡çš„çš„symbol
        symbols = adapter._get_trading_symbols()
        primary_symbol = symbols[0].split(":")[0] if symbols else None
        if not primary_symbol:
            return
        btc_symbol = btc_instrument_id.split(".")[0] if "." in btc_instrument_id else "BTCUSDT-PERP"

        # æ„å»ºCSVæ–‡ä»¶è·¯å¾„
        data_dir = Path(base_dir) / "data" / "raw"
        primary_csv = data_dir / f"{primary_symbol}_{timeframe}.csv"
        btc_csv = data_dir / f"{btc_symbol}_{timeframe}.csv"

        # æ‰§è¡Œå¯¹é½æ£€æŸ¥
        tui = get_tui()
        use_tui = is_tui_enabled()

        if use_tui:
            tui.add_log(f"æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½: {primary_symbol} vs {btc_symbol}", "INFO")
        else:
            logger.info(f"ğŸ” æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½: {primary_symbol} vs {btc_symbol}")

        is_aligned, error_msg = validate_multi_instrument_alignment(
            primary_csv, btc_csv, min_alignment_rate=0.95, logger=logger
        )

        if not is_aligned:
            if use_tui:
                tui.add_log(f"æ•°æ®å¯¹é½è­¦å‘Š: {error_msg}", "ERROR")
                tui.add_log("å»ºè®®: æ£€æŸ¥æ•°æ®æºæˆ–é‡æ–°ä¸‹è½½æ•°æ®", "INFO")
            else:
                logger.error(f"âš ï¸  æ•°æ®å¯¹é½è­¦å‘Š: {error_msg}")
                logger.info("   å»ºè®®: æ£€æŸ¥æ•°æ®æºæˆ–é‡æ–°ä¸‹è½½æ•°æ®")
        else:
            if use_tui:
                tui.add_log("æ•°æ®å¯¹é½éªŒè¯é€šè¿‡", "INFO")
            else:
                logger.info("âœ… æ•°æ®å¯¹é½éªŒè¯é€šè¿‡")

    except Exception as e:
        tui = get_tui()
        if is_tui_enabled():
            tui.add_log(f"å¤šæ ‡çš„å¯¹é½æ£€æŸ¥å¤±è´¥: {e}", "WARNING")
        else:
            logger.warning(f"å¤šæ ‡çš„å¯¹é½æ£€æŸ¥å¤±è´¥: {e}")
