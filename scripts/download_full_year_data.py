"""
ä¸‹è½½å®Œæ•´å¹´åº¦æ•°æ®ï¼ˆè‡ªåŠ¨åˆ†æ‰¹å¤„ç†ï¼‰

ç”¨æ³•:
    uv run python scripts/download_full_year_data.py --symbols SOLUSDT --year 2024
    uv run python scripts/download_full_year_data.py --symbols BTCUSDT ETHUSDT --start-date 2024-01-01 --end-date 2024-12-31
"""

import argparse
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.data_management.data_fetcher import BinanceFetcher
import pandas as pd


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ä¸‹è½½å®Œæ•´å¹´åº¦æ•°æ®ï¼ˆè‡ªåŠ¨åˆ†æ‰¹å¤„ç†ï¼‰")

    parser.add_argument(
        "--symbols",
        nargs="+",
        required=True,
        help="äº¤æ˜“å¯¹åˆ—è¡¨ (å¦‚: BTCUSDT ETHUSDT SOLUSDT)",
    )

    parser.add_argument(
        "--year",
        type=int,
        help="å¹´ä»½ (å¦‚: 2024)",
    )

    parser.add_argument(
        "--start-date",
        type=str,
        help="å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)",
    )

    parser.add_argument(
        "--end-date",
        type=str,
        help="ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/raw",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: data/raw)",
    )

    parser.add_argument(
        "--batch-days",
        type=int,
        default=40,
        help="æ¯æ‰¹ä¸‹è½½çš„å¤©æ•° (é»˜è®¤: 40å¤©ï¼Œçº¦960æ¡1hæ•°æ®)",
    )

    return parser.parse_args()


def date_to_timestamp_ms(date_str: str) -> int:
    """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ï¿½ï¿½æ¯«ç§’æ—¶é—´æˆ³"""
    dt = datetime.strptime(date_str, "%Y-%m-%d")
    return int(dt.timestamp() * 1000)


def download_data_in_batches(
    fetcher: BinanceFetcher,
    symbol: str,
    start_date: str,
    end_date: str,
    batch_days: int,
    market_type: str,
) -> pd.DataFrame:
    """
    åˆ†æ‰¹ä¸‹è½½æ•°æ®ï¼ˆå¤„ç† Binance API 1000 æ¡é™åˆ¶ï¼‰

    Args:
        fetcher: BinanceFetcher å®ä¾‹
        symbol: äº¤æ˜“å¯¹
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        batch_days: æ¯æ‰¹å¤©æ•°
        market_type: å¸‚åœºç±»å‹ (spot/futures)

    Returns:
        åˆå¹¶åçš„å®Œæ•´æ•°æ®
    """
    all_data = []
    current_date = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")

    batch_num = 1
    while current_date < end_dt:
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»“æŸæ—¶é—´
        batch_end = min(current_date + timedelta(days=batch_days), end_dt)

        start_ts = int(current_date.timestamp() * 1000)
        end_ts = int(batch_end.timestamp() * 1000)

        print(f"  æ‰¹æ¬¡ {batch_num}: {current_date.date()} ~ {batch_end.date()}", end=" ")

        try:
            batch_data = fetcher.fetch_ohlcv(
                symbol=symbol,
                timeframe="1h",
                start_time=start_ts,
                end_time=end_ts,
                limit=1000,
                market_type=market_type,
            )

            if len(batch_data) > 0:
                all_data.append(batch_data)
                print(f"âœ… ({len(batch_data)} æ¡)")
            else:
                print("âš ï¸ (æ— æ•°æ®)")

            # é¿å…è§¦å‘ API é™æµ
            time.sleep(0.5)

        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")

        current_date = batch_end
        batch_num += 1

    if not all_data:
        raise ValueError("æœªä¸‹è½½åˆ°ä»»ä½•æ•°æ®")

    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®
    combined = pd.concat(all_data, ignore_index=True)

    # å»é‡ï¼ˆå¯èƒ½æœ‰é‡å ï¼‰
    combined = combined.drop_duplicates(subset=["timestamp"], keep="first")

    # æŒ‰æ—¶é—´æ’åº
    combined = combined.sort_values("timestamp").reset_index(drop=True)

    return combined


def download_funding_rate_in_batches(
    fetcher: BinanceFetcher,
    symbol: str,
    start_date: str,
    end_date: str,
    batch_days: int,
) -> pd.DataFrame:
    """
    åˆ†æ‰¹ä¸‹è½½èµ„é‡‘è´¹ç‡æ•°æ®

    Args:
        fetcher: BinanceFetcher å®ä¾‹
        symbol: äº¤æ˜“å¯¹
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        batch_days: æ¯æ‰¹å¤©æ•°

    Returns:
        åˆå¹¶åçš„å®Œæ•´æ•°æ®
    """
    all_data = []
    current_date = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")

    batch_num = 1
    while current_date < end_dt:
        batch_end = min(current_date + timedelta(days=batch_days), end_dt)

        start_ts = int(current_date.timestamp() * 1000)
        end_ts = int(batch_end.timestamp() * 1000)

        print(f"  æ‰¹æ¬¡ {batch_num}: {current_date.date()} ~ {batch_end.date()}", end=" ")

        try:
            batch_data = fetcher.fetch_funding_rate(
                symbol=symbol,
                start_time=start_ts,
                end_time=end_ts,
                limit=1000,
            )

            if len(batch_data) > 0:
                all_data.append(batch_data)
                print(f"âœ… ({len(batch_data)} æ¡)")
            else:
                print("âš ï¸ (æ— æ•°æ®)")

            time.sleep(0.5)

        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")

        current_date = batch_end
        batch_num += 1

    if not all_data:
        raise ValueError("æœªä¸‹è½½åˆ°ä»»ä½•èµ„é‡‘è´¹ç‡æ•°æ®")

    combined = pd.concat(all_data, ignore_index=True)
    combined = combined.drop_duplicates(subset=["timestamp"], keep="first")
    combined = combined.sort_values("timestamp").reset_index(drop=True)

    return combined


def download_pair_data(
    fetcher: BinanceFetcher,
    symbol: str,
    start_date: str,
    end_date: str,
    output_dir: Path,
    batch_days: int,
):
    """
    ä¸‹è½½å•ä¸ªå¸å¯¹çš„å®Œæ•´æ•°æ®

    Args:
        fetcher: BinanceFetcher å®ä¾‹
        symbol: äº¤æ˜“å¯¹
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        output_dir: è¾“å‡ºç›®å½•
        batch_days: æ¯æ‰¹å¤©æ•°
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š å¤„ç†äº¤æ˜“å¯¹: {symbol}")
    print(f"{'=' * 60}")

    # 1. ä¸‹è½½ç°è´§æ•°æ®
    print("\n[1/3] ä¸‹è½½ç°è´§æ•°æ®...")
    try:
        spot_data = download_data_in_batches(
            fetcher=fetcher,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            batch_days=batch_days,
            market_type="spot",
        )

        spot_dir = output_dir / symbol
        spot_dir.mkdir(parents=True, exist_ok=True)
        spot_file = spot_dir / f"binance-{symbol}-1h-{start_date}_{end_date}.csv"

        spot_data.to_csv(spot_file, index=False)
        print(f"\nâœ… ç°è´§æ•°æ®å·²ä¿å­˜: {spot_file}")
        print(f"   æ€»æ•°æ®è¡Œæ•°: {len(spot_data)}")
        print(f"   æ—¶é—´èŒƒå›´: {spot_data['timestamp'].min()} ~ {spot_data['timestamp'].max()}")
    except Exception as e:
        print(f"\nâŒ ç°è´§æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        return False

    # 2. ä¸‹è½½æ°¸ç»­åˆçº¦æ•°æ®
    print("\n[2/3] ä¸‹è½½æ°¸ç»­åˆçº¦æ•°æ®...")
    try:
        futures_data = download_data_in_batches(
            fetcher=fetcher,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            batch_days=batch_days,
            market_type="futures",
        )

        futures_dir = output_dir / f"{symbol}-PERP"
        futures_dir.mkdir(parents=True, exist_ok=True)
        futures_file = futures_dir / f"binance-{symbol}-PERP-1h-{start_date}_{end_date}.csv"

        futures_data.to_csv(futures_file, index=False)
        print(f"\nâœ… æ°¸ç»­åˆçº¦æ•°æ®å·²ä¿å­˜: {futures_file}")
        print(f"   æ€»æ•°æ®è¡Œæ•°: {len(futures_data)}")
        print(f"   æ—¶é—´èŒƒå›´: {futures_data['timestamp'].min()} ~ {futures_data['timestamp'].max()}")
    except Exception as e:
        print(f"\nâŒ æ°¸ç»­åˆçº¦æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        return False

    # 3. ä¸‹è½½èµ„é‡‘è´¹ç‡æ•°æ®
    print("\n[3/3] ä¸‹è½½èµ„é‡‘è´¹ç‡æ•°æ®...")
    try:
        funding_data = download_funding_rate_in_batches(
            fetcher=fetcher,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            batch_days=batch_days * 3,  # èµ„é‡‘è´¹ç‡æ•°æ®æ›´ç¨€ç–ï¼Œå¯ä»¥ç”¨æ›´å¤§çš„æ‰¹æ¬¡
        )

        funding_file = futures_dir / f"binance-{symbol}-PERP-funding_rate-{start_date}_{end_date}.csv"

        funding_data.to_csv(funding_file, index=False)
        print(f"\nâœ… èµ„é‡‘è´¹ç‡æ•°æ®å·²ä¿å­˜: {funding_file}")
        print(f"   æ€»æ•°æ®è¡Œæ•°: {len(funding_data)}")
        print(f"   æ—¶é—´èŒƒå›´: {funding_data['timestamp'].min()} ~ {funding_data['timestamp'].max()}")

        # æ˜¾ç¤ºèµ„é‡‘è´¹ç‡ç»Ÿè®¡
        print("\nğŸ“ˆ èµ„é‡‘è´¹ç‡ç»Ÿè®¡:")
        print(f"   å¹³å‡å¹´åŒ–: {funding_data['funding_rate_annual'].mean():.2f}%")
        print(f"   æœ€å¤§å¹´åŒ–: {funding_data['funding_rate_annual'].max():.2f}%")
        print(f"   æœ€å°å¹´åŒ–: {funding_data['funding_rate_annual'].min():.2f}%")
    except Exception as e:
        print(f"\nâŒ èµ„é‡‘è´¹ç‡æ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        return False

    print(f"\nâœ… {symbol} æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆ!")
    return True


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # ç¡®å®šæ—¥æœŸèŒƒå›´
    if args.year:
        start_date = f"{args.year}-01-01"
        end_date = f"{args.year}-12-31"
    elif args.start_date and args.end_date:
        start_date = args.start_date
        end_date = args.end_date
    else:
        print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®š --year æˆ– (--start-date å’Œ --end-date)")
        return 1

    print("=" * 60)
    print("ğŸš€ å®Œæ•´å¹´åº¦æ•°æ®ä¸‹è½½å·¥å…·ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰")
    print("=" * 60)
    print("\né…ç½®ä¿¡æ¯:")
    print(f"  äº¤æ˜“å¯¹: {', '.join(args.symbols)}")
    print(f"  æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_days} å¤©")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åˆ›å»º fetcher
    fetcher = BinanceFetcher()

    # ä¸‹è½½æ¯ä¸ªäº¤æ˜“å¯¹çš„æ•°æ®
    success_count = 0
    failed_symbols = []

    for symbol in args.symbols:
        success = download_pair_data(
            fetcher=fetcher,
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            output_dir=output_dir,
            batch_days=args.batch_days,
        )

        if success:
            success_count += 1
        else:
            failed_symbols.append(symbol)

    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸‹è½½æ±‡æ€»")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}/{len(args.symbols)}")
    if failed_symbols:
        print(f"âŒ å¤±è´¥: {', '.join(failed_symbols)}")
    print("=" * 60)

    return 0 if success_count == len(args.symbols) else 1


if __name__ == "__main__":
    sys.exit(main())
