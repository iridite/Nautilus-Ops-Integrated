"""
æ•°æ®éªŒè¯å·¥å…·æ¨¡å—

æä¾›é€šç”¨çš„æ•°æ®å¼‚å¸¸æ£€æµ‹å’ŒéªŒè¯åŠŸèƒ½ï¼Œå¯è¢«å¤šä¸ªç­–ç•¥å¤ç”¨ã€‚
é€‚ç”¨äº OIã€Funding Rateã€ä»·æ ¼ç­‰å¸‚åœºæ•°æ®çš„å¼‚å¸¸æ£€æµ‹ã€‚
"""

import logging
from decimal import Decimal
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

class DataValidator:
    """
    æ•°æ®éªŒè¯å™¨

    åŠŸèƒ½ï¼š
    - æ£€æµ‹æ•°æ®æœ‰æ•ˆæ€§ï¼ˆNaNã€Noneã€0ã€è´Ÿæ•°ï¼‰
    - æ£€æµ‹æ•°æ®å‰§çƒˆå˜åŒ–ï¼ˆæ¢æœˆã€æ•°æ®é”™è¯¯ï¼‰
    - æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆè¶…å‡ºåˆç†èŒƒå›´ï¼‰
    - æä¾›çµæ´»çš„é˜ˆå€¼é…ç½®
    """

    def __init__(
        self,
        spike_threshold: float = 0.5,
        enable_logging: bool = True,
    ):
        """
        åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨

        Parameters
        ----------
        spike_threshold : float
            æ•°æ®çªå˜é˜ˆå€¼ï¼ˆé»˜è®¤ 50%ï¼‰
        enable_logging : bool
            æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•
        """
        self.spike_threshold = spike_threshold
        self.enable_logging = enable_logging
        self._last_valid_value: Optional[Decimal] = None

    def validate_oi(
        self, oi_value: Optional[Decimal], logger=None
    ) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ OIï¼ˆæŒä»“é‡ï¼‰æ•°æ®

        Parameters
        ----------
        oi_value : Optional[Decimal]
            OI æ•°æ®å€¼
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥ 1: æ•°æ®æœ‰æ•ˆæ€§
        if oi_value is None or oi_value <= 0:
            error_msg = f"Invalid OI data: {oi_value}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # æ£€æŸ¥ 2: å‰§çƒˆå˜åŒ–æ£€æµ‹ï¼ˆæ¢æœˆã€æ•°æ®é”™è¯¯ï¼‰
        if self._last_valid_value is not None and self._last_valid_value > 0:
            change_pct = abs(float((oi_value - self._last_valid_value) / self._last_valid_value))
            if change_pct > self.spike_threshold:
                error_msg = (
                    f"OI spike detected: {change_pct:.1%} change "
                    f"(from {self._last_valid_value:.0f} to {oi_value:.0f}). "
                    f"Possible contract roll or data error."
                )
                if logger and self.enable_logging:
                    logger.warning(f"âš ï¸  {error_msg}")
                return False, error_msg

        # æ•°æ®é€šè¿‡éªŒè¯
        self._last_valid_value = oi_value
        return True, None

    def validate_funding_rate(
        self,
        funding_annual: Optional[Decimal],
        max_abs_value: float = 500.0,
        spike_threshold: float = 200.0,
        logger=None,
    ) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ Funding Rateï¼ˆèµ„é‡‘è´¹ç‡ï¼‰æ•°æ®

        Parameters
        ----------
        funding_annual : Optional[Decimal]
            å¹´åŒ–èµ„é‡‘è´¹ç‡
        max_abs_value : float
            æœ€å¤§ç»å¯¹å€¼ï¼ˆé»˜è®¤ Â±500%ï¼‰
        spike_threshold : float
            çªå˜é˜ˆå€¼ï¼ˆé»˜è®¤ 200%ï¼‰
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥ 1: æ•°æ®æœ‰æ•ˆæ€§
        if funding_annual is None:
            error_msg = "Invalid Funding Rate data: None"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # æ£€æŸ¥ 2: å¼‚å¸¸å€¼æ£€æµ‹
        if abs(float(funding_annual)) > max_abs_value:
            error_msg = (
                f"Abnormal Funding Rate: {funding_annual:.2f}% (annual), "
                f"exceeds Â±{max_abs_value}% threshold. Possible data error."
            )
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # æ£€æŸ¥ 3: å‰§çƒˆå˜åŒ–æ£€æµ‹
        if self._last_valid_value is not None:
            change = abs(float(funding_annual - self._last_valid_value))
            if change > spike_threshold:
                error_msg = (
                    f"Funding Rate spike detected: {change:.1f}% change "
                    f"(from {self._last_valid_value:.2f}% to {funding_annual:.2f}%). "
                    f"Possible data error."
                )
                if logger and self.enable_logging:
                    logger.warning(f"âš ï¸  {error_msg}")
                return False, error_msg

        # æ•°æ®é€šè¿‡éªŒè¯
        self._last_valid_value = funding_annual
        return True, None

    def validate_price(
        self,
        price: Optional[Decimal],
        min_price: Optional[Decimal] = None,
        max_price: Optional[Decimal] = None,
        logger=None,
    ) -> tuple[bool, Optional[str]]:
        """
        éªŒè¯ä»·æ ¼æ•°æ®

        Parameters
        ----------
        price : Optional[Decimal]
            ä»·æ ¼æ•°æ®
        min_price : Optional[Decimal]
            æœ€å°åˆç†ä»·æ ¼
        max_price : Optional[Decimal]
            æœ€å¤§åˆç†ä»·æ ¼
        logger : Logger, optional
            æ—¥å¿—è®°å½•å™¨

        Returns
        -------
        tuple[bool, Optional[str]]
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥ 1: æ•°æ®æœ‰æ•ˆæ€§
        if price is None or price <= 0:
            error_msg = f"Invalid price data: {price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # æ£€æŸ¥ 2: ä»·æ ¼èŒƒå›´
        if min_price is not None and price < min_price:
            error_msg = f"Price {price} below minimum {min_price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        if max_price is not None and price > max_price:
            error_msg = f"Price {price} above maximum {max_price}"
            if logger and self.enable_logging:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # æ£€æŸ¥ 3: å‰§çƒˆå˜åŒ–æ£€æµ‹
        if self._last_valid_value is not None and self._last_valid_value > 0:
            change_pct = abs(float((price - self._last_valid_value) / self._last_valid_value))
            if change_pct > self.spike_threshold:
                error_msg = (
                    f"Price spike detected: {change_pct:.1%} change "
                    f"(from {self._last_valid_value:.2f} to {price:.2f}). "
                    f"Possible data error or circuit breaker."
                )
                if logger and self.enable_logging:
                    logger.warning(f"âš ï¸  {error_msg}")
                return False, error_msg

        # æ•°æ®é€šè¿‡éªŒè¯
        self._last_valid_value = price
        return True, None

    def reset(self):
        """é‡ç½®éªŒè¯å™¨çŠ¶æ€"""
        self._last_valid_value = None


def validate_multi_instrument_alignment(
    primary_csv: Path,
    secondary_csv: Path,
    min_alignment_rate: float = 0.95,
    logger=None
) -> tuple[bool, Optional[str]]:
    """
    éªŒè¯å¤šæ ‡çš„æ•°æ®æ—¶é—´æˆ³å¯¹é½

    ç”¨äºæ£€æŸ¥ç­–ç•¥éœ€è¦çš„å¤šä¸ªæ ‡çš„æ•°æ®æ˜¯å¦æ—¶é—´åŒæ­¥ï¼Œé˜²æ­¢æœªæ¥å‡½æ•°ã€‚
    ä¾‹å¦‚ï¼šDK_Alpha_Trendç­–ç•¥éœ€è¦ä¸»æ ‡çš„(ETH)å’ŒBTCæ•°æ®å¯¹é½ã€‚

    Parameters
    ----------
    primary_csv : Path
        ä¸»æ ‡çš„CSVæ–‡ä»¶è·¯å¾„
    secondary_csv : Path
        è¾…åŠ©æ ‡çš„CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚BTCï¼‰
    min_alignment_rate : float
        æœ€å°å¯¹é½ç‡é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰
    logger : Logger, optional
        æ—¥å¿—è®°å½•å™¨

    Returns
    -------
    tuple[bool, Optional[str]]
        (æ˜¯å¦å¯¹é½, é”™è¯¯ä¿¡æ¯)

    Examples
    --------
    >>> is_aligned, error = validate_multi_instrument_alignment(
    ...     Path("data/raw/ETHUSDT-PERP_1-DAY.csv"),
    ...     Path("data/raw/BTCUSDT-PERP_1-DAY.csv")
    ... )
    >>> if not is_aligned:
    ...     print(f"æ•°æ®å¯¹é½é—®é¢˜: {error}")
    """
    import pandas as pd

    try:
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not primary_csv.exists():
            error_msg = f"ä¸»æ ‡çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {primary_csv}"
            if logger:
                logger.error(error_msg)
            return False, error_msg

        if not secondary_csv.exists():
            error_msg = f"è¾…åŠ©æ ‡çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {secondary_csv}"
            if logger:
                logger.error(error_msg)
            return False, error_msg

        # åŠ è½½æ—¶é—´æˆ³åˆ—ï¼ˆè‡ªåŠ¨æ£€æµ‹åˆ—åï¼‰
        primary_df = pd.read_csv(primary_csv)
        secondary_df = pd.read_csv(secondary_csv)

        # æ£€æµ‹æ—¶é—´åˆ—å
        time_cols = ['timestamp', 'datetime', 'time', 'date']
        primary_time_col = None
        secondary_time_col = None

        for col in time_cols:
            if col in primary_df.columns:
                primary_time_col = col
                break

        for col in time_cols:
            if col in secondary_df.columns:
                secondary_time_col = col
                break

        if not primary_time_col:
            error_msg = f"ä¸»æ ‡çš„æ•°æ®ç¼ºå°‘æ—¶é—´åˆ—: {primary_csv}"
            if logger:
                logger.error(error_msg)
            return False, error_msg

        if not secondary_time_col:
            error_msg = f"è¾…åŠ©æ ‡çš„æ•°æ®ç¼ºå°‘æ—¶é—´åˆ—: {secondary_csv}"
            if logger:
                logger.error(error_msg)
            return False, error_msg

        # æå–æ—¶é—´æˆ³é›†åˆ
        primary_timestamps = set(primary_df[primary_time_col])
        secondary_timestamps = set(secondary_df[secondary_time_col])

        # è®¡ç®—å¯¹é½æƒ…å†µ
        common_timestamps = primary_timestamps & secondary_timestamps
        primary_count = len(primary_timestamps)
        secondary_count = len(secondary_timestamps)
        common_count = len(common_timestamps)

        # è®¡ç®—å¯¹é½ç‡ï¼ˆåŸºäºä¸»æ ‡çš„ï¼‰
        alignment_rate = common_count / primary_count if primary_count > 0 else 0.0

        # è®°å½•è¯¦ç»†ä¿¡æ¯
        if logger:
            logger.info(
                f"æ•°æ®å¯¹é½æ£€æŸ¥: "
                f"ä¸»æ ‡çš„={primary_count}æ¡, "
                f"è¾…åŠ©æ ‡çš„={secondary_count}æ¡, "
                f"å…±åŒ={common_count}æ¡, "
                f"å¯¹é½ç‡={alignment_rate:.1%}"
            )

        # æ£€æŸ¥å¯¹é½ç‡
        if alignment_rate < min_alignment_rate:
            error_msg = (
                f"æ•°æ®å¯¹é½ç‡è¿‡ä½: {alignment_rate:.1%} < {min_alignment_rate:.1%}\n"
                f"ä¸»æ ‡çš„: {primary_csv.name} ({primary_count}æ¡)\n"
                f"è¾…åŠ©æ ‡çš„: {secondary_csv.name} ({secondary_count}æ¡)\n"
                f"å…±åŒæ—¶é—´æˆ³: {common_count}æ¡\n"
                f"å»ºè®®: æ£€æŸ¥æ•°æ®æºæˆ–é‡æ–°ä¸‹è½½æ•°æ®"
            )
            if logger:
                logger.warning(f"âš ï¸  {error_msg}")
            return False, error_msg

        # å¯¹é½ç‡åˆæ ¼
        if logger:
            logger.info(f"âœ… æ•°æ®å¯¹é½éªŒè¯é€šè¿‡: {alignment_rate:.1%}")

        return True, None

    except Exception as e:
        error_msg = f"æ•°æ®å¯¹é½éªŒè¯å¤±è´¥: {e}"
        if logger:
            logger.error(error_msg)
        return False, error_msg





def prepare_data_feeds(args, adapter, base_dir, universe_symbols: set):
    """å‡†å¤‡æ•°æ®æµï¼ˆéªŒè¯æˆ–è·å–ï¼‰"""
    from utils.data_file_checker import check_single_data_file

    from .data_manager import run_batch_data_retrieval

    if args.skip_data_check:
        logger.info("â© Skipping data validation")
        return

    logger.info("ğŸ“Š Data Validation")

    venue = adapter.get_venue().lower()
    start_date = adapter.get_start_date()
    end_date = adapter.get_end_date()
    timeframe = adapter.get_main_timeframe()

    # ä»ç­–ç•¥é…ç½®è·å–äº¤æ˜“å¯¹è±¡åˆ—è¡¨
    symbols_to_check = universe_symbols if universe_symbols else set(adapter._get_trading_symbols())

    missing_symbols = []
    for symbol in symbols_to_check:
        exists, _ = check_single_data_file(
            symbol.split(":")[0], start_date, end_date, timeframe, venue, base_dir
        )
        if not exists:
            missing_symbols.append(symbol.split(":")[0])

    if missing_symbols:
        logger.info(f"ğŸ“¥ {len(missing_symbols)} symbols need data")
        run_batch_data_retrieval(
            missing_symbols, start_date, end_date, timeframe, venue, base_dir
        )
    else:
        logger.info("âœ… All data files present\n")


def _check_multi_instrument_alignment(adapter, base_dir: Path, venue: str, timeframe: str):
    """æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½ï¼ˆå¦‚æœç­–ç•¥éœ€è¦ï¼‰"""
    import logging

    logger = logging.getLogger(__name__)

    try:
        # è·å–ç­–ç•¥é…ç½®
        config = adapter.build_backtest_config()
        strategy_params = config.strategy.params if hasattr(config.strategy, 'params') else config.strategy

        # æ£€æŸ¥æ˜¯å¦æœ‰è¾…åŠ©æ ‡çš„é…ç½®ï¼ˆå¦‚ btc_instrument_idï¼‰
        btc_instrument_id = getattr(strategy_params, 'btc_instrument_id', None)
        if not btc_instrument_id:
            return  # ç­–ç•¥ä¸éœ€è¦å¤šæ ‡çš„å¯¹é½æ£€æŸ¥

        # æå–ä¸»æ ‡çš„å’ŒBTCæ ‡çš„çš„symbol
        symbols = adapter._get_trading_symbols()
        primary_symbol = symbols[0].split(":")[0] if symbols else None
        if not primary_symbol:
            return
        btc_symbol = btc_instrument_id.split(".")[0] if "." in btc_instrument_id else "BTCUSDT-PERP"

        # æ„å»ºCSVæ–‡ä»¶è·¯å¾„
        data_dir = Path(base_dir) / "data" / "raw"
        primary_csv = data_dir / f"{primary_symbol}_{timeframe}.csv"
        btc_csv = data_dir / f"{btc_symbol}_{timeframe}.csv"

        # æ‰§è¡Œå¯¹é½æ£€æŸ¥
        logger.debug(f"ğŸ” æ£€æŸ¥å¤šæ ‡çš„æ•°æ®å¯¹é½: {primary_symbol} vs {btc_symbol}")
        is_aligned, error_msg = validate_multi_instrument_alignment(
            primary_csv, btc_csv, min_alignment_rate=0.95, logger=logger
        )

        if not is_aligned:
            logger.error(f"âš ï¸  æ•°æ®å¯¹é½è­¦å‘Š: {error_msg}")
            logger.info("   å»ºè®®: æ£€æŸ¥æ•°æ®æºæˆ–é‡æ–°ä¸‹è½½æ•°æ®")
        else:
            logger.info("âœ… æ•°æ®å¯¹é½éªŒè¯é€šè¿‡")

    except Exception as e:
        logger.warning(f"å¤šæ ‡çš„å¯¹é½æ£€æŸ¥å¤±è´¥: {e}")
